{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/CMK8s-Samples/sample_notebooks/005%20EstimatorStep/pipeline-estimator-step.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use EstimatorStep in AML Pipeline\n",
    "\n",
    "This notebook shows how to use the EstimatorStep with Azure Machine Learning Pipelines. Estimator is a convenient object in Azure Machine Learning that wraps run configuration information to help simplify the tasks of specifying how a script is executed.\n",
    "\n",
    "\n",
    "## Prerequisite:\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](https://aka.ms/pl-config) to:\n",
    "    * install the AML SDK\n",
    "    * create a workspace and its configuration file (`config.json`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the aml dependency\n",
    "\n",
    "Run the script below or skip it if you already installed\n",
    "\n",
    "pip install --disable-pip-version-check --extra-index-url https://azuremlsdktestpypi.azureedge.net/CmAks-Compute-Test/D58E86006C65 azureml_contrib_itp\n",
    "\n",
    "pip install azureml-dataprep azureml-explain-model azureml-train-automl-runtime azureml-widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get started. First let's import some Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.container_registry import ContainerRegistry\n",
    "from azureml.train.estimator import Estimator\n",
    "import azureml.contrib.core\n",
    "from azureml.contrib.core.compute.cmakscompute import CmAksCompute\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Datastore\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')\n",
    "\n",
    "# Default datastore\n",
    "def_blob_store = ws.get_default_datastore() \n",
    "# The following call GETS the Azure Blob Store associated with your workspace.\n",
    "# Note that workspaceblobstore is **the name of this store and CANNOT BE CHANGED and must be used as is** \n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "print(\"Blobstore's name: {}\".format(def_blob_store.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload data to default datastore\n",
    "Default datastore on workspace is the Azure  File storage. The workspace has a Blob storage associated with it as well. Let's upload a file to each of these storages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_default_datastore() gets the default Azure Blob Store associated with your workspace.\n",
    "# Here we are reusing the def_blob_store object we obtained earlier\n",
    "def_blob_store.upload_files([\"./20news.pkl\"], target_path=\"20newsgroups\", overwrite=True)\n",
    "print(\"Upload call completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach existing Compute Target\n",
    "You will need to attach a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model.\n",
    "\n",
    "Just replace the cluster_name with your own aks name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.contrib.core.compute.cmakscompute import CmAksCompute\n",
    "for key, target in ws.compute_targets.items():\n",
    "    if type(target) is CmAksCompute:\n",
    "        print('Found compute target:{}\\ttype:{}\\tprovisioning_state:{}\\tlocation:{}'.format(target.name, target.type, target.provisioning_state, target.location))\n",
    "\n",
    "cluster_name = 'your-aks-name'\n",
    "\n",
    "cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "print('Found existing compute target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a simple script\n",
    "We have already created a simple \"hello world\" script. This is the script that we will submit through the estimator pattern. It prints a hello-world message, and if Azure ML SDK is installed, it will also logs an array of values ([Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build an Estimator object\n",
    "Estimator by default will attempt to use Docker-based execution. You can also enable Docker and let estimator pick the default CPU image supplied by Azure ML for execution. You can target an Cmk8s cluster (or any other supported compute target types). You can also customize the conda environment by adding conda and/or pip packages.\n",
    "\n",
    "> Note: The arguments to the entry script used in the Estimator object should be specified as *list* using\n",
    "    'estimator_entry_script_arguments' parameter when instantiating EstimatorStep. Estimator object's parameter\n",
    "    'script_params' accepts a dictionary. However 'estimator_entry_script_arguments' parameter expects arguments as\n",
    "    a list.\n",
    "\n",
    "> Estimator object initialization involves specifying a list of DataReference objects in its 'inputs' parameter.\n",
    "    In Pipelines, a step can take another step's output or DataReferences as input. So when creating an EstimatorStep,\n",
    "    the parameters 'inputs' and 'outputs' need to be set explicitly and that will override 'inputs' parameter\n",
    "    specified in the Estimator object.\n",
    "   \n",
    "> The best practice is to use separate folders for scripts and its dependent files for each step and specify that folder as the `source_directory` for the step. This helps reduce the size of the snapshot created for the step (only the specific folder is snapshotted). Since changes in any files in the `source_directory` would trigger a re-upload of the snapshot, this helps keep the reuse of the step when there are no changes in the `source_directory` of the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "datareference-remarks-sample"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.core import PipelineData\n",
    "\n",
    "def_blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "\n",
    "input_data = DataReference(\n",
    "    datastore=def_blob_store,\n",
    "    data_reference_name=\"input_data\",\n",
    "    path_on_datastore=\"20newsgroups/20news.pkl\")\n",
    "\n",
    "output = PipelineData(\"output\", datastore=def_blob_store)\n",
    "\n",
    "source_directory = 'estimator_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "est = Estimator(source_directory=source_directory, \n",
    "                compute_target=cpu_cluster, \n",
    "                entry_script='dummy_train.py', \n",
    "                conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an EstimatorStep\n",
    "[EstimatorStep](https://docs.microsoft.com/en-us/python/api/azureml-pipeline-steps/azureml.pipeline.steps.estimator_step.estimatorstep?view=azure-ml-py) adds a step to run Estimator in a Pipeline.\n",
    "\n",
    "- **name:** Name of the step\n",
    "- **estimator:** Estimator object\n",
    "- **estimator_entry_script_arguments:** \n",
    "- **runconfig_pipeline_params:** Override runconfig properties at runtime using key-value pairs each with name of the runconfig property and PipelineParameter for that property\n",
    "- **inputs:** Inputs\n",
    "- **outputs:** Output is list of PipelineData\n",
    "- **compute_target:** Compute target to use \n",
    "- **allow_reuse:** Whether the step should reuse previous results when run with the same settings/inputs. If this is false, a new run will always be generated for this step during pipeline execution.\n",
    "- **version:** Optional version tag to denote a change in functionality for the step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "estimatorstep-remarks-sample"
    ]
   },
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import EstimatorStep\n",
    "\n",
    "est_step = EstimatorStep(name=\"Estimator_Train\", \n",
    "                         estimator=est, \n",
    "                         estimator_entry_script_arguments=[\"--datadir\", input_data, \"--output\", output],\n",
    "                         runconfig_pipeline_params=None, \n",
    "                         inputs=[input_data], \n",
    "                         outputs=[output], \n",
    "                         compute_target=cpu_cluster,\n",
    "                         allow_reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Submit the Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "pipeline = Pipeline(workspace=ws, steps=[est_step])\n",
    "pipeline_run = Experiment(ws, 'Estimator_sample').submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Run Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(pipeline_run).show()"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sanpil"
   }
  ],
  "category": "tutorial",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Custom"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Azure ML"
  ],
  "friendly_name": "Azure Machine Learning Pipeline with EstimatorStep",
  "kernelspec": {
   "display_name": "cmk8s",
   "language": "python",
   "name": "cmk8s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "order_index": 7,
  "star_tag": [
   "None"
  ],
  "tags": [
   "None"
  ],
  "task": "Demonstrates the use of EstimatorStep"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}