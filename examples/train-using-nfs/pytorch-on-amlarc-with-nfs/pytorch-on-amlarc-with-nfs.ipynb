{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Train using Distributed Pytorch on Azure Arc-enabled Machine Learning with NFS-mounted data\n",
    "\n",
    "This example notebook demonstrates how to train a Deep Learning model using Pytorch and data stored on an NFS server.\n",
    "\n",
    "* Setup an NFS Server\n",
    "* Download training data to the NFS Server\n",
    "* Configure NFS Server mounts on your Kubernetes Cluster\n",
    "* Setup your connection to Azure Machine Learning\n",
    "* Create the necessary Azure Machine Learning objects\n",
    "* Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup an NFS Server\n",
    "This notebook assumes that you either have access to an existing NFS server or know how to set one up.  Setting up and configuring NFS is beyond\n",
    "the scope of this example.  To complete this notebook you will need to know the address of your NFS server and know how to mount it locally so that it is accessible to this notebook.\n",
    "\n",
    "Once you have a working NFS server mount, configure the 'nfs_mount_path' variable below to point to it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nfs_mount_path = '/nfs_share'\n",
    "\n",
    "import os\n",
    "mnist_dir = os.path.join(nfs_mount_path, 'mnist')\n",
    "os.makedirs(mnist_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download training data to the NFS Server\n",
    "This step uses the Torchvision utilities (from PyTorch) to download the MNIST data to the NFS server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%pip install torchvision==0.7.0\n",
    "\n",
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "datasets.MNIST(mnist_dir, train=True, download=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cofigure NFS Server mounts on your Kubernetes Cluster\n",
    "\n",
    "Follow the instructions [here](../amlarc-nfs-setup/README.md) to configure your Azure Arc-enabled Machine Learning cluster to mount your NFS server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup your connection to Azure Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Connect to the Workspace described by local configuration\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "create workspace"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the necessary Azure Machine Learning objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an Experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = 'train-on-amlarc-with-nfs'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Docker-based environment with Pytorch installed\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env_name = 'AzureML-PyTorch-1.6-CPU'\n",
    "myenv = Environment.get(workspace=ws, name=env_name)\n",
    "\n",
    "# Enable Docker\n",
    "docker_config = DockerConfiguration(use_docker=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify the name of an existing Azure Arc-enabled Machine Learning compute target\n",
    "amlarc_cluster = 'amlarc'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "\n",
    "# Configure the run.  For this example we will use the NFS data path set above.\n",
    "backend = 'Gloo'\n",
    "dist_config = PyTorchConfiguration(communication_backend=backend, node_count = 3)\n",
    "\n",
    "src = ScriptRunConfig(source_directory='scripts', \n",
    "                      script='train.py', \n",
    "                      compute_target=amlarc_cluster,\n",
    "                      environment=myenv,\n",
    "                      arguments=['--data-dir', mnist_dir, '--backend', backend],\n",
    "                      docker_runtime_config=docker_config,\n",
    "                      distributed_job_config=dist_config)\n",
    " \n",
    "run = experiment.submit(config=src)\n",
    "run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: if you need to cancel a run, you can follow [these instructions](https://aka.ms/aml-docs-cancel-run)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shows output of the run on stdout.\n",
    "run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "nigup"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "Train on Azure Machine Learning Compute",
  "index_order": 1,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('reinforcement-learning': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Submit a run on Azure Machine Learning Compute.",
  "interpreter": {
   "hash": "35af1fdeebffda251ef6c74d8fab833455f029e14e41c2b8f9cd1519f2f9f445"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}