{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Train using Azure Arc-enabled Machine Learning with NFS-mounted data\n",
    "\n",
    "This example notebook demonstrates how to train a simple Machine Learning model from data stored on an NFS server.\n",
    "For this example we will be training a simple model using scikit-learn.\n",
    "\n",
    "* Setup an NFS Server\n",
    "* Copy the Iris data to the NFS Server\n",
    "* Configure NFS Server mounts on your Kubernetes Cluster\n",
    "* Setup your connection to Azure Machine Learning\n",
    "* Create the necessary Azure Machine Learning objects\n",
    "* Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup an NFS Server\n",
    "This notebook assumes that you either have access to an existing NFS server or know how to set one up.  Setting up and configuring NFS is beyond\n",
    "the scope of this example.  To complete this notebook you will need to know the address of your NFS server and know how to copy files onto it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nfs_mount_path = '/nfs_share'\n",
    "\n",
    "import os, shutil\n",
    "iris_dir = os.path.join(nfs_mount_path, 'iris')\n",
    "shutil.rmtree(iris_dir, ignore_errors=True)\n",
    "os.makedirs(iris_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Copy the Iris data to the NFS Server\n",
    "The iris.csv file (located in this directory) contains the training data.  The following code copies this file into your NFS share."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "shutil.copyfile('iris.csv', os.path.join(iris_dir, 'iris.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cofigure NFS Server mounts on your Kubernetes Cluster\n",
    "\n",
    "Follow the instructions [here](../amlarc-nfs-setup/README.md) to configure your Azure Arc-enabled Machine Learning cluster to mount your NFS server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup your connection to Azure Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Connect to the Workspace described by local configuration\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "create workspace"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the necessary Azure Machine Learning objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an Experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = 'train-on-amlarc-with-nfs'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create a Docker-based environment with scikit-learn installed\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env_name = 'AzureML-sklearn-0.24-ubuntu18.04-py37-cuda11-gpu'\n",
    "myenv = Environment.get(workspace=ws, name=env_name)\n",
    "\n",
    "# Enable Docker\n",
    "docker_config = DockerConfiguration(use_docker=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Specify the name of an existing Azure Arc-enabled Machine Learning compute target\n",
    "amlarc_cluster = 'amlarc'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Configure the run.  For this example we will use the NFS data path set above.\n",
    "src = ScriptRunConfig(source_directory='scripts', \n",
    "                      script='train.py', \n",
    "                      compute_target=amlarc_cluster,\n",
    "                      environment=myenv,\n",
    "                      arguments=['--data-dir', iris_dir],\n",
    "                      docker_runtime_config=docker_config)\n",
    " \n",
    "run = experiment.submit(config=src)\n",
    "run"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: if you need to cancel a run, you can follow [these instructions](https://aka.ms/aml-docs-cancel-run)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shows output of the run on stdout.\n",
    "run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "dasommer"
   }
  ],
  "category": "training",
  "compute": [
   "AMLArc"
  ],
  "datasets": [
   "Iris"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "Scikit-learn"
  ],
  "friendly_name": "Train a model on Iris using Scikit-learn and NFS-mounted data",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Train a model on Iris using Scikit-learn and NFS-mounted data"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}