{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  Train using Azure Arc-enabled Machine Learning with NFS-mounted data\n",
    "\n",
    "This example notebook demonstrates how to train a simple Machine Learning model from data stored on an NFS server.\n",
    "For this example we will be training a simple model using scikit-learn.\n",
    "\n",
    "* Setup an NFS Server\n",
    "* Copy the Iris data to the NFS Server\n",
    "* Configure NFS Server mounts on your Kubernetes Cluster\n",
    "* Setup your connection to Azure Machine Learning\n",
    "* Create the necessary Azure Machine Learning objects\n",
    "* Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup an NFS Server\n",
    "This notebook assumes that you either have access to an existing NFS server or know how to set one up.  Setting up and configuring NFS is beyond\n",
    "the scope of this example.  To complete this notebook you will need to know the address of your NFS server and know how to copy files onto it."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nfs_mount_path = '/nfs_share'\n",
    "\n",
    "import os\n",
    "iris_dir = os.path.join(nfs_mount_path, 'iris')\n",
    "os.makedirs(iris_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Copy the Iris data to the NFS Server\n",
    "The iris.csv file (located in this directory) contains the training data.  The following code copies this file into your NFS share."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copyfile('iris.csv', os.path.join(iris_dir, 'iris.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cofigure NFS Server mounts on your Kubernetes Cluster\n",
    "\n",
    "Follow the instructions [here](../amlarc-nfs-setup/README.md) to configure your Azure Arc-enabled Machine Learning cluster to mount your NFS server."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup your connection to Azure Machine Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-core 1.32.0 (/disks/4TB/code/e2e/reinforcement-learning/lib/python3.6/site-packages), Requirement.parse('azureml-core~=1.30.0')).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDK version: 1.32.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Connect to the Workspace described by local configuration\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dasommer-ml-eus\n",
      "dasommer\n",
      "eastus\n",
      "4aaa645c-5ae2-4ae9-a17a-84b9023bc56a\n"
     ]
    }
   ],
   "metadata": {
    "tags": [
     "create workspace"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the necessary Azure Machine Learning objects"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Create an Experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = 'train-on-amlarc-with-nfs'\n",
    "experiment = Experiment(workspace = ws, name = experiment_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create a Docker-based environment with scikit-learn installed\n",
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = Environment(\"myenv\")\n",
    "myenv.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn', 'packaging'])\n",
    "\n",
    "# Enable Docker\n",
    "docker_config = DockerConfiguration(use_docker=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Specify the name of an existing Azure Arc-enabled Machine Learning compute target\n",
    "amlarc_cluster = 'amlarc'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Submit a Training Run"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Configure the run.  For this example we will use the NFS data path set above.\n",
    "src = ScriptRunConfig(source_directory='scripts', \n",
    "                      script='train.py', \n",
    "                      compute_target=amlarc_cluster,\n",
    "                      environment=myenv,\n",
    "                      arguments=['--data-dir', iris_dir],\n",
    "                      docker_runtime_config=docker_config)\n",
    " \n",
    "run = experiment.submit(config=src)\n",
    "run"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Run(Experiment: train-on-amlarc-with-nfs,\n",
       "Id: train-on-amlarc-with-nfs_1629765768_2475dc17,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Starting)"
      ],
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>train-on-amlarc-with-nfs</td><td>train-on-amlarc-with-nfs_1629765768_2475dc17</td><td>azureml.scriptrun</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/train-on-amlarc-with-nfs_1629765768_2475dc17?wsid=/subscriptions/4aaa645c-5ae2-4ae9-a17a-84b9023bc56a/resourcegroups/dasommer/workspaces/dasommer-ml-eus&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: if you need to cancel a run, you can follow [these instructions](https://aka.ms/aml-docs-cancel-run)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Shows output of the run on stdout.\n",
    "run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.get_metrics()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "nigup"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "Diabetes"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "None"
  ],
  "friendly_name": "Train on Azure Machine Learning Compute",
  "index_order": 1,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('reinforcement-learning': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Submit a run on Azure Machine Learning Compute.",
  "interpreter": {
   "hash": "35af1fdeebffda251ef6c74d8fab833455f029e14e41c2b8f9cd1519f2f9f445"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}