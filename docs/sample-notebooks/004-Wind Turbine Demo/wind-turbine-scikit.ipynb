{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind Turbine: Azure ML with scikit-learn\n",
    "\n",
    "In this notebook, we'll build and analyze a new model to predict wind turbine wake winds.\n",
    "\n",
    "It is important to consider the two main conditions that influence the presence of wind wake:\n",
    "1. Overall wind farm direction and turbine wind direction are both are between 40° - 45° degrees.\n",
    "1. High difference that's greater than one minute between `TurbineSpeedStdDev` and `WindSpeedStdDev`.\n",
    "\n",
    "The above conditions are well known features to predict when `Wind Wake` is affecting the wind turbine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "Before you begin with this lab, please make sure to follow the steps below:\n",
    "1. Locate the default datastore for the workspace, this can be done by authenticating against the workspace (cell #2) and execute the following command: `ws.get_default_datastore()`\n",
    "1. Locate the dataset parquet file in the lab materials: `TrainingDataset.parquet`\n",
    "1. Upload the dataset for this lab to the default datastore for the workspace. You can do this via Azure Portal or via Microsoft Azure Storage Explorer.\n",
    "1. Ensure you have the correct version of `scikit-learn` and `joblib` installed. To install these dependencies, you can execute the cell below, skip this step if the dependencies are already installed.\n",
    "1. Restart your kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn==0.22.1 joblib==0.14.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure ML\n",
    "\n",
    "In the next cell, we will create a new Workspace config object using the `<subscription_id>`, `<resource_group_name>`, and `<workspace_name>`. This will fetch the matching Workspace and prompt you for authentication. Please click on the link and input the provided details.\n",
    "\n",
    "For more information on **Workspace**, please visit: [Microsoft Workspace Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py)\n",
    "\n",
    "`<subscription_id>` = You can get this ID from the landing page of your Resource Group.\n",
    "\n",
    "`<resource_group_name>` = This is the name of your Resource Group.\n",
    "\n",
    "`<workspace_name>` = This is the name of your Workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "project_folder = './scripts'\n",
    "\n",
    "try:    \n",
    "    interactive_auth = InteractiveLoginAuthentication(tenant_id=\"<tenant_id>\")\n",
    "    # Get instance of the Workspace and write it to config file\n",
    "    ws = Workspace(\n",
    "        subscription_id = '<subscription_id>', \n",
    "        resource_group = '<resource_group>', \n",
    "        workspace_name = '<workspace_name>',\n",
    "        auth = interactive_auth)\n",
    "\n",
    "    # Writes workspace config file\n",
    "    ws.write_config()\n",
    "    \n",
    "    print('Library configuration succeeded')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch our data\n",
    "\n",
    "Let's retrieve our dataset from the default workspace Datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.data.datapath import DataPath\n",
    "from azureml.core import Datastore\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "\n",
    "datastore_path = [DataPath(datastore, '*.parquet')]\n",
    "\n",
    "tabular = Dataset.Tabular.from_parquet_files(path=datastore_path)\n",
    "tabular = tabular.register(workspace=ws, \n",
    "                           name='wind_turbine_training', \n",
    "                           create_new_version=True)\n",
    "tabular = Dataset.get_by_name(ws, name='wind_turbine_training')\n",
    "print(tabular.version)\n",
    "data = tabular.to_pandas_dataframe()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll take a subset of our data and then proceed to visualize it to better understand any patterns and trends that might exist to drive good ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = tabular.take_sample(probability=0.4, seed=123).to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description\n",
    "\n",
    "Describe our current dataset. The table below shows the different statistical values for our training subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbine Wind Direction\n",
    "\n",
    "Let's take a look at the Turbine Wind Direction distribution against the Wind Direction Angle. As we can see, we have a considerable alteration between 40° and 50° degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "hstyle={\"rwidth\":0.75,'edgecolor':'black'}\n",
    "\n",
    "# Analyze distribution of TurbineWindDirection in the dataset\n",
    "fig, ax = plt.subplots()\n",
    "sns.distplot(subset[['TurbineWindDirection']], ax=ax, \n",
    "             hist_kws=hstyle).set_title(\"Turbine Wind Direction Distribuition\")\n",
    "ax.set_xlim(0,360)\n",
    "ax.set(xlabel=\"Wind Direction Angle\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbine Wind Direction vs Alter Blades\n",
    "\n",
    "Let's take a look at how our training dataset conducts for `Alter Blades` against the `Wind Direction Angle`. It is very clear that between 40° and 50° degrees we have a clear spike of `True` values for `Alter Blades`. Keep in mind, that the target column for our prediction is `Alter Blades`, this column will enable us to identify a wake condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(subset, col='AlterBlades')\n",
    "g.map(sns.distplot, 'TurbineWindDirection', hist_kws=hstyle)\n",
    "g.set(xlabel=\"Wind Direction Angle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbine Speed\n",
    "\n",
    "Let's take a look at the Turbine Speed distribution. In the chart, we can observe the distribution has values between 10 and 25 km/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(subset[['TurbineSpeedAverage']], ax=ax, \n",
    "             hist_kws=hstyle).set_title(\"Average Turbine Speed Distribuition\")\n",
    "ax.set(xlabel=\"Average Turbine Speed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbine Speed Standard Deviation vs Alter Blades\n",
    "\n",
    "Let's take a look at how our training dataset behaves for `Alter Blades` against the `Turbine Speed Standard Deviation`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how age influences whether customers have responded to insurance campaigns\n",
    "g = sns.FacetGrid(subset, col='AlterBlades')\n",
    "g.map(sns.distplot, 'TurbineSpeedStdDev', hist_kws=hstyle)\n",
    "g.set(xlabel=\"Turbine Speed Std Dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Speed\n",
    "\n",
    "Let's take a look at the Wind Speed distribution. In the chart, we can observe the distribution has values between 10 and 25 km/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(subset[['WindSpeedAverage']], ax=ax, \n",
    "             hist_kws=hstyle).set_title(\"Average Wind Speed Distribuition\")\n",
    "ax.set(xlabel=\"Average Wind Speed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind Speed Standard Deviation vs Alter Blades\n",
    "\n",
    "Let's take a look at how our training dataset behaves for `Alter Blades` against the `Turbine Speed Standard Deviation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how age influences whether customers have responded to insurance campaigns\n",
    "g = sns.FacetGrid(subset, col='AlterBlades')\n",
    "g.map(sns.distplot, 'WindSpeedStdDev', hist_kws=hstyle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate AlterBlades rows true values\n",
    "\n",
    "Let's create a Facet Grid to understand the trends that our `True` values from the `Alter Blades` column has against other features in the dataset such as:\n",
    "1. Turbine Speed Standard Deviation\n",
    "1. Turbine Wind Direction\n",
    "1. Wind Speed Standard Deviation\n",
    "\n",
    "As we are able to see, when `Turbine Wind Direction` is around 40° to 45° degrees, it is a very good indication for an `Alter Blades: True` value. Also, we are able to see that high `Turbine Speed Standard Deviation` versus a low `Wind Speed Standard Deviation` are also key features to achieve a `True` value in the `Alter Blades` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alterBlades = subset.loc[subset.AlterBlades]\n",
    "g = sns.FacetGrid(alterBlades, col='AlterBlades')\n",
    "g.map(plt.hist, 'TurbineSpeedStdDev')\n",
    "g.set(xlabel=\"Turbine Speed Std Dev\")\n",
    "\n",
    "display(g)\n",
    "\n",
    "g = sns.FacetGrid(alterBlades, col='AlterBlades')\n",
    "g.map(plt.hist, 'TurbineWindDirection')\n",
    "g.set(xlabel=\"Turbine Wind Direction Angle\")\n",
    "\n",
    "display(g)\n",
    "\n",
    "g = sns.FacetGrid(alterBlades, col='AlterBlades')\n",
    "g.map(plt.hist, 'WindSpeedStdDev')\n",
    "g.set(xlabel=\"Wind Speed Std Dev\")\n",
    "\n",
    "display(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot Wind Speed Std Dev, Turbine Speed Std Dev and Alter Blades\n",
    "\n",
    "Let's place our key features in a Pair plot to analyze their trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how age and category gardening spend is influenced by age and region\n",
    "sns.pairplot(subset, vars=['WindSpeedStdDev', 'TurbineSpeedStdDev'], hue='AlterBlades')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create experiment\n",
    "\n",
    "In our script, there are three distinct sections:\n",
    "1. Setting up the scikit-learn logistic regression model pipeline (including encoding our features).\n",
    "1. Analyzing and logging the results of the model training.\n",
    "1. Running the model explainer to understand the key model drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $project_folder/train.py\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Fetch current run\n",
    "run = Run.get_context()\n",
    "    \n",
    "# Fetch dataset from the run by name\n",
    "dataset = run.input_datasets['training']\n",
    "\n",
    "# Convert dataset to Pandas data frame\n",
    "X_train, X_test, y_train, y_test = split_dataset(dataset)\n",
    "\n",
    "# Setup scikit-learn pipeline\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, list(X_train.columns.values))])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression())])\n",
    "\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# Analyze model performance\n",
    "analyze_model(clf, X_test, y_test)\n",
    "\n",
    "# Save model\n",
    "model_id = save_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Workspace Experiment\n",
    "\n",
    "The Experiment constructor allows to create an experiment instance. The constructor takes in the current workspace, which is fetched by calling `Workspace.from_config()` and an experiment name. \n",
    "\n",
    "For more information on **Experiment**, please visit: [Microsoft Experiment Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# Get an instance of the Workspace from the config file\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "experiment_name = 'wake-detection-experiment'\n",
    "\n",
    "# Create Experiment\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Automated ML Compute cluster\n",
    "\n",
    "Firstly, check for the existence of the cluster. If it already exists, we are able to reuse it. Checking for the existence of the cluster can be performed by calling the constructor `ComputeTarget()` with the current workspace and name of the cluster.\n",
    "\n",
    "In case the cluster does not exist, the next step will be to provide a configuration for the new AML cluster by calling the function `AmlCompute.provisioning_configuration()`. It takes as parameters the VM size and the max number of nodes that the cluster can scale up to. After the configuration has executed, `ComputeTarget.create()` should be called with the previously configuration object and the workspace object.\n",
    "\n",
    "For more information on **ComputeTarget**, please visit: [Microsoft get_data Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py)\n",
    "\n",
    "For more information on **AmlCompute**, please visit: [Microsoft get_data Documentation](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.akscompute?view=azure-ml-py)\n",
    "\n",
    "\n",
    "**Note:** Please wait for the execution of the cell to finish before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Create AML CPU Compute Cluster\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name='cpucluster')\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS12_v2',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    compute_target = ComputeTarget.create(ws, 'cpucluster', compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Experiment\n",
    "\n",
    "We'll use remote compute for this job. We need to install a couple of extra libraries, including those required for model interpretability.\n",
    "\n",
    "The `experiment.submit()` function is called to send the experiment for execution. The only parameter received by this function is the `Estimator` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.sklearn import SKLearn\n",
    "\n",
    "estimator = SKLearn(source_directory=project_folder,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='train.py',\n",
    "                    inputs=[tabular.as_named_input('training')],\n",
    "                    pip_packages=['azureml-dataprep[fuse,pandas]','joblib==0.14.1','azureml-interpret','azureml-contrib-interpret','matplotlib','scikit-learn==0.22.1','seaborn'])\n",
    "\n",
    "run = experiment.submit(estimator)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor Experiment\n",
    "\n",
    "The creation of an object of type `Run` will enable us to observe the experiment’s progress and results. The object is created by calling the constructor `Run()`. It takes, as arguments, the experiment and the identifier of the run to fetch. After the object has been instantiated, the `RunDetails()` function will retrieve the progress, metrics, and tasks for the specified run. They will be displayed by calling the function `show()` over the mentioned object.\n",
    "\n",
    "**Note:** Please wait for the execution of the cell to finish before moving forward. (Status should be **Completed**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "run = Run(experiment, run.id)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode dataset and download trained model\n",
    "\n",
    "First step is to encode our training data to take the shape expected by the Onnx converter. Next, download the model obtained from the best run. In order to download the model, the function `download_model()` should be called. This will take care of downloading the model obtained from the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from scripts.utils import *\n",
    "\n",
    "# Convert dataset to Pandas data frame\n",
    "X_train, X_test, y_train, y_test = split_dataset(tabular)\n",
    "model = download_model(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model to Onnx format\n",
    "\n",
    "Export the Sklearn model to Onnx format by using `skl2onnx`. This step will output an Onnx model that we will be able to publish to the Azure SQL Edge Database Instance to use along with our `PREDICT` statement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skl2onnx\n",
    "import onnxmltools\n",
    "\n",
    "# Convert the scikit model to onnx format\n",
    "onnx_model = skl2onnx.convert_sklearn(model, 'Wind Turbine Dataset', convert_dataframe_schema(X_train))\n",
    "# Save the onnx model locally\n",
    "onnx_model_path = 'windturbinewake.model.onnx'\n",
    "onnxmltools.utils.save_model(onnx_model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to Azure Blob Storage\n",
    "\n",
    "Let's save our Onnx model to the default workspace Datastore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datastore.upload_files(files=[onnx_model_path],\n",
    "                         overwrite=True,\n",
    "                         show_progress=True)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
