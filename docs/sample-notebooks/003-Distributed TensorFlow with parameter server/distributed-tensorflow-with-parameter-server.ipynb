{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation. All rights reserved.\n",
        "\n",
        "Licensed under the MIT License."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/how-to-use-azureml/ml-frameworks/tensorflow/distributed-tensorflow-with-parameter-server/distributed-tensorflow-with-parameter-server.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distributed TensorFlow with parameter server\n",
        "In this tutorial, you will train a TensorFlow model on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset using native [distributed TensorFlow](https://www.tensorflow.org/deploy/distributed)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
        "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration notebook](../../../../configuration.ipynb) to:\n",
        "    * install the AML SDK\n",
        "    * create a workspace and its configuration file (`config.json`)\n",
        "* Review the [tutorial](../train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb) on single-node TensorFlow training using the SDK"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check core SDK version number\n",
        "import azureml.core\n",
        "\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.18.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1605482214964
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diagnostics\n",
        "Opt-in diagnostics for better experience, quality, and security of future releases."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.telemetry import set_diagnostics_collection\n",
        "\n",
        "set_diagnostics_collection(send_diagnostics=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Turning diagnostics collection on. \n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "tags": [
          "Diagnostics"
        ],
        "gather": {
          "logged": 1605482217546
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize workspace\n",
        "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: akse-attach-ws1\n",
            "Azure region: eastus2euap\n",
            "Subscription id: 5abfd9c4-ec8c-4db9-acd4-c762dce93508\n",
            "Resource group: akse-ws-rg\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1605482222110
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create or Attach existing AmlCompute\n",
        "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
        "\n",
        "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
        "\n",
        "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "# from azureml.contrib.core.compute.arckubernetescompute import ArcKubernetesCompute\n",
        "from azureml.contrib.core.compute.cmakscompute import CmAksCompute\n",
        "\n",
        "# choose a name for your Kubernetes compute\n",
        "compute_name = 'aks-gpu-profile'\n",
        "compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
        "\n",
        "# use get_status() to get a detailed status for the current AmlCompute. \n",
        "print(compute_target, compute_target.get_status())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CmAksCompute(workspace=Workspace.create(name='akse-attach-ws1', subscription_id='5abfd9c4-ec8c-4db9-acd4-c762dce93508', resource_group='akse-ws-rg'), name=aks-gpu-profile, id=/subscriptions/5abfd9c4-ec8c-4db9-acd4-c762dce93508/resourceGroups/akse-ws-rg/providers/Microsoft.MachineLearningServices/workspaces/akse-attach-ws1/computes/aks-gpu-profile, type=CmAks, provisioning_state=Succeeded, location=eastus2euap, tags=None) Succeeded\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1605482246224
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model on the remote compute\n",
        "Now that we have the cluster ready to go, let's run our distributed training job."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a project directory\n",
        "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "project_folder = './tf-distr-ps'\n",
        "os.makedirs(project_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1605482254073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the training script `tf_mnist_replica.py` into this project directory."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.copy('tf_mnist_replica.py', project_folder)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'./tf-distr-ps/tf_mnist_replica.py'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1605482259084
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an experiment\n",
        "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed TensorFlow tutorial. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "\n",
        "experiment_name = 'tf-distr-ps-aks'\n",
        "experiment = Experiment(ws, name=experiment_name)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1605482268586
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an environment\n",
        "\n",
        "In this tutorial, we will use one of Azure ML's curated TensorFlow environments for training. [Curated environments](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments#use-a-curated-environment) are available in your workspace by default. Specifically, we will use the TensorFlow 1.13 GPU curated environment."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "tf_env = Environment.get(ws, name='AzureML-TensorFlow-1.13-GPU')"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1605482271931
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure the training job\n",
        "\n",
        "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on.\n",
        "\n",
        "In order to execute a distributed TensorFlow run with the parameter server strategy, you must create a `TensorflowConfiguration` object and pass it to the `distributed_job_config` parameter of the ScriptRunConfig constructor. The below code configures a distributed TensorFlow run with `2` workers and `1` parameter server."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.core.runconfig import TensorflowConfiguration\n",
        "\n",
        "src = ScriptRunConfig(source_directory=project_folder,\n",
        "                      script='tf_mnist_replica.py',\n",
        "                      arguments=['--num_gpus', 1, '--train_steps', 500],\n",
        "                      compute_target=compute_target,\n",
        "                      environment=tf_env,\n",
        "                      distributed_job_config=TensorflowConfiguration(worker_count=2, parameter_server_count=1))"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1605482277450
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submit job\n",
        "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run = experiment.submit(src)\n",
        "print(run)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: tf-distr-ps-aks,\n",
            "Id: tf-distr-ps-aks_1605482284_50608a58,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Starting)\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1605482282054
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monitor your run\n",
        "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, you can block until the script has completed training before running more code."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "run.wait_for_completion(show_output=True) # this provides a verbose log"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "index_order": 1,
    "exclude_from_index": false,
    "task": "Use the TensorFlow estimator to train a model using distributed training",
    "deployment": [
      "None"
    ],
    "authors": [
      {
        "name": "minxia"
      }
    ],
    "kernel_info": {
      "name": "python3-azureml"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "compute": [
      "AML Compute"
    ],
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "tags": [
      "None"
    ],
    "datasets": [
      "MNIST"
    ],
    "categories": [
      "how-to-use-azureml",
      "ml-frameworks",
      "tensorflow"
    ],
    "category": "training",
    "framework": [
      "TensorFlow"
    ],
    "friendly_name": "Distributed TensorFlow with parameter server",
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}