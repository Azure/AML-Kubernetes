{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* [Setup Azure Arc-enabled Machine Learning Training and Inferencing on AKS on Azure Stack HCI](https://github.com/Azure/AML-Kubernetes/tree/master/docs/AKS-HCI/AML-ARC-Compute.md)\n",
    "\n",
    "* [Setup NFS Server on Azure Stack HCI and Use your Data and run managed Machine Learning Experiments On-Premises](https://github.com/Azure/AML-Kubernetes/tree/master/docs/AKS-HCI/Train-AzureArc.md)\n",
    "\n",
    "* Make sure the NFS Server is mounted on the notebook execution machine. In this notebook, it will upload the training data to NFS Server.\n",
    "\n",
    "*    Last but not least, you need to be able to run a Notebook. (azureml-core, azureml-opendatasets, numpy, matplotlib, requests are required)\n",
    "\n",
    "   If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at [here](https://github.com/Azure/MachineLearningNotebooks) first. This sets you up with a working config file that has information on your workspace, subscription id, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize AzureML workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`. \n",
    "\n",
    "If you haven't done already please go to `config.json` file and fill in your workspace information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace,  ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download mnist data\n",
    "\n",
    "Perform pip install azureml-opendatasets to get the open dataset package, use this function to download mnist data later. This allows you to avoid download the data again when you run this notebook multiple times. The actual download time may take 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.opendatasets import MNIST\n",
    "import os\n",
    "\n",
    "def download_mnist_data():\n",
    "    data_folder = os.path.join(os.getcwd(), 'mnist_data')\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "    mnist_file_dataset = MNIST.get_file_dataset()\n",
    "    path = mnist_file_dataset.download(data_folder, overwrite=True)\n",
    "    downloaded_folder = os.path.dirname(path[0])\n",
    "    print(\"downloaded to\", downloaded_folder)\n",
    "    \n",
    "    return downloaded_folder\n",
    "\n",
    "downloaded_folder = download_mnist_data()\n",
    "downloaded_folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the mnist data to NFS server (Optional)\n",
    "\n",
    "The above download_mnist_data() function will download four files t10k-images-idx3-ubyte.gz, t10k-labels-idx1-ubyte.gz, train-images-idx3-ubyte.gz and train-labels-idx1-ubyte.gz to downloaded_folder.  Your next step is to copy these files to NFS server.\n",
    "Run run this step, you need to make sure the NFS path is mounted on the notebook execution machine. Replace `<NFS Mount Point on notebook execution machine>` with the correct path.\n",
    "\n",
    "This step is optional, you can use other ways, such as directly downloading training data on NFS server to prepare the mnist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_mount_path = \"<NFS Mount Point on notebook execution machine>\"\n",
    "\n",
    "import os, shutil\n",
    "mnist_dir = os.path.join(nfs_mount_path, 'mnist')\n",
    "shutil.rmtree(mnist_dir, ignore_errors=True)\n",
    "os.makedirs(mnist_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(downloaded_folder):\n",
    "    filepath = os.path.join(downloaded_folder, filename)\n",
    "    destpath = os.path.join(mnist_dir, filename)\n",
    "    print(f\"Copying files from {filepath} to {destpath}\")\n",
    "    shutil.copyfile(filepath, destpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup compute target\n",
    "\n",
    "Find the attach name for the Arc enabled AKS-HCI in your AzureML workspace.\n",
    "\n",
    "attach_name is the attached name for your AKS-HCI cluster you setup in [this step](https://github.com/Azure/AML-Kubernetes/blob/master/docs/AKS-HCI/AML-ARC-Compute.md#attach-your-azure-arc-enabled-cluster-to-your-azure-machine-learning-workspace-as-a-compute-target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import KubernetesCompute\n",
    "\n",
    "attach_name = \"<NAME_OF_AML_ATTACHED_COMPUTE_OF_YOUR_ASH_CLUSTER>\"\n",
    "arcK_target = KubernetesCompute(ws, attach_name)\n",
    "\n",
    "print(f\"compute target id in endpoint yaml: azureml:{arcK_target.name}, instance type name in deployment yaml: {arcK_target.default_instance_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training job and submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'mnist-demo'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized environment\n",
    "\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "# to install required packages\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job\n",
    "\n",
    "`<MountPathOnTrainingPod>` is the same as the mountPath defined in mount-config.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "data_folder = \"<MountPathOnTrainingPod>\"+\"/mnist\" # training data are saved to <mountPoint>/mnist (have to use / as the path separator)\n",
    "\n",
    "args = ['--data-folder', data_folder, '--regularization', 0.5]\n",
    "script_folder =  \"mnist_script\"\n",
    "src = ScriptRunConfig(source_directory=script_folder,\n",
    "                      script='train.py', \n",
    "                      arguments=args,\n",
    "                      compute_target=arcK_target,\n",
    "                      environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job\n",
    "\n",
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model\n",
    "\n",
    "Register the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='sklearn_mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register model\n",
    "model = run.register_model(model_name=model_name,\n",
    "                           model_path='outputs/sklearn_mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model named \"sklearn_mnist\" should be registered in your AzureML workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "model = Model(ws, model_name)\n",
    "model_id = f\"azureml:{model.name}:{model.version}\"\n",
    "print(f\"Get {model.name}, latest version {model.version}, id in deployment.yml: {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy and score a machine learning model by using a managed online endpoint\n",
    "\n",
    "Currently, amlarc inference is only supported with Azure Machine Learning CI (v2). Please follow [doc](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-train-cli?view=azure-devops#prerequisites) to configure the prerequisites. This notebook will invoke Azure Machine Learning CI (v2) directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = '<sklearn-mnist endpoint name>'\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "prefix = Path(os.getcwd())\n",
    "endpoint_file = str(prefix.joinpath(\"endpoint.yml\"))\n",
    "deployment_file = str(prefix.joinpath(\"deployment.yml\"))\n",
    "print(f\"Using Endpoint file: {endpoint_file}, Deployment file: {deployment_file} please replace <modelId> (e.g. azureml:sklearn_mnist:1), <instanceTypeName> (e.g. defaultInstanceType) and <computeTargetName> (e.g. azureml:amlarc-compute) according above output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to **replace the properties in deployment.yml**, including,\n",
    "* `<modelId>`: example value: azureml:sklearn_mnist:1\n",
    "* `<instanceTypeName>`: example value: defaultInstanceType\n",
    "\n",
    "Need to **replace the properties in endpoint.yml**, including,\n",
    "* `<computeTargetName>`: example value: azureml:amlarc-compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.run(f\"az ml online-endpoint create -n {endpoint} -f {endpoint_file} -w {ws.name} -g {ws.resource_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.run(f\"az ml online-endpoint show -n {endpoint} -w {ws.name} -g {ws.resource_group}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.run(f\"az ml online-deployment create -n blue --endpoint {endpoint} -f {deployment_file} -w {ws.name} -g {ws.resource_group} --all-traffic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with inputs\n",
    "\n",
    "Here you may use the image from test asset. The first 30 images and its labels are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist_script.utils import load_data\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), 'mnist_data')\n",
    "\n",
    "X_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-images-idx3-ubyte.gz\"), recursive=True)[0], False) / 255.0\n",
    "y_test = load_data(glob.glob(os.path.join(data_folder,\"**/t10k-labels-idx1-ubyte.gz\"), recursive=True)[0], True).reshape(-1)\n",
    "\n",
    "# show first 30 figures\n",
    "\n",
    "count = 0\n",
    "sample_size = 30\n",
    "plt.figure(figsize = (16, 6))\n",
    "# for i in np.random.permutation(X_test.shape[0])[:sample_size]:\n",
    "for i in range(30):\n",
    "    count = count + 1\n",
    "    plt.subplot(1, sample_size, count)\n",
    "    plt.axhline('')\n",
    "    plt.axvline('')\n",
    "    plt.text(x = 10, y = -10, s = y_test[i], fontsize = 18)\n",
    "    plt.imshow(X_test[i].reshape(28, 28), cmap = plt.cm.Greys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get score_uri and access_token from AZ CLI (Currently only Azure Machine Learning CLI (v2) supported)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score_url and access_token from AZ CLI\n",
    "import helpers\n",
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "cmd = f\"az ml online-endpoint show -n {endpoint} -w {ws.name} -g {ws.resource_group}\"\n",
    "properties = helpers.run(cmd, return_output=True, no_output=True)\n",
    "\n",
    "cmd = f\"az ml online-endpoint get-credentials -n {endpoint} -w {ws.name} -g {ws.resource_group}\"\n",
    "credentials = helpers.run(cmd, return_output=True, no_output=True)\n",
    "\n",
    "print(f\"Got endpoint and credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the second image: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "prop_response = json.loads(properties.replace(os.linesep,\"\"))\n",
    "score_uri = prop_response[\"scoring_uri\"]\n",
    "\n",
    "cred_response = json.loads(credentials.replace(os.linesep, \"\"))\n",
    "access_token = cred_response[\"accessToken\"]\n",
    "\n",
    "import requests\n",
    "# second number should be 2\n",
    "test = json.dumps({\"data\": X_test.tolist()[1:2]})\n",
    "headers = {'Content-Type': 'application/json', 'Authorization': f\"Bearer {access_token}\"}\n",
    "r = requests.post(score_uri, data=test, headers=headers)\n",
    "print(f\"predictions: {r.json()}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc402497f0168b24575e2ffafe64cd34c507b9a7fab971a93b09782ae565c5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
