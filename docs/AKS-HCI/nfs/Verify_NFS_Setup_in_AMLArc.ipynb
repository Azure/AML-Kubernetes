{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the NFS Setup in AMLArc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* [Setup Azure Arc-enabled Machine Learning Training and Inferencing on AKS on Azure Stack HCI](https://github.com/msftcoderdjw/AML-Kubernetes/blob/jiadu/aks-hci/docs/AKS-HCI/AML-ARC-Compute.md)\n",
    "\n",
    "* [Setup NFS Server on Azure Stack HCI and Use your Data and run managed Machine Learning Experiments On-Premises](https://github.com/msftcoderdjw/AML-Kubernetes/blob/jiadu/aks-hci/docs/AKS-HCI/Train-AzureArc.md)\n",
    "\n",
    "* (Optional) Upload some training data to NFS Server for verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize AzureML workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`. \n",
    "\n",
    "If you haven't done already please go to `config.json` file and fill in your workspace information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace,  ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup compute target\n",
    "\n",
    "Find the Arc K8S Resource Id and replace the resource id below.\n",
    "\n",
    "e.g. /subscriptions/`<subscriptionId>`/resourceGroups/`<resourceGroupName>`/providers/Microsoft.Kubernetes/connectedClusters/`<clusterName>`\n",
    "\n",
    "Using 'kubectl create ns aml' to create a namespace in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import KubernetesCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for your Azure Arc-enabled Kubernetes compute\n",
    "amlarc_compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"<ArcComputeName>\")\n",
    "\n",
    "# resource ID for your Azure Arc-enabled Kubernetes cluster\n",
    "resource_id = \"/subscriptions/<subscriptionId>/resourceGroups/<resourceGroupName>/providers/Microsoft.Kubernetes/connectedClusters/<clusterName>\"\n",
    "\n",
    "if amlarc_compute_name in ws.compute_targets:\n",
    "   amlarc_compute = ws.compute_targets[amlarc_compute_name]\n",
    "   if amlarc_compute and type(amlarc_compute) is KubernetesCompute:\n",
    "      print(\"found compute target: \" + amlarc_compute_name)\n",
    "else:\n",
    "   print(\"creating new compute target...\")\n",
    "   ns = \"aml\"\n",
    "    \n",
    "   instance_types = {\n",
    "    \"defaultInstanceType\": {\n",
    "      \"nodeSelector\": None,\n",
    "      \"resources\": {\n",
    "        \"requests\": {\n",
    "          \"cpu\": \"1\",\n",
    "          \"memory\": \"4Gi\",\n",
    "          \"nvidia.com/gpu\": 0\n",
    "        },\n",
    "        \"limits\": {\n",
    "          \"cpu\": \"1\",\n",
    "          \"memory\": \"4Gi\",\n",
    "          \"nvidia.com/gpu\": 0\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "   amlarc_attach_configuration = KubernetesCompute.attach_configuration(resource_id = resource_id, namespace = ns, default_instance_type=\"defaultInstanceType\", instance_types = instance_types)\n",
    " \n",
    "   amlarc_compute = ComputeTarget.attach(ws, amlarc_compute_name, amlarc_attach_configuration)\n",
    "\n",
    " \n",
    "   amlarc_compute.wait_for_completion(show_output=True)\n",
    "    \n",
    "   # For a more detailed view of current KubernetesCompute status, use get_status()\n",
    "   print(amlarc_compute.get_status().serialize())\n",
    "\n",
    "print(f\"compute target id in endpoint yaml: azureml:{amlarc_compute.name}, instance type name in endpoint yaml: {amlarc_compute.default_instance_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import KubernetesCompute\n",
    "\n",
    "attach_name = amlarc_compute_name\n",
    "arcK_target = KubernetesCompute(ws, attach_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the training job and submit\n",
    "\n",
    "This experiment will list the contents of the NFS mounting point on training pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'nfs-demo'\n",
    "\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized environment\n",
    "\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "# to install required packages\n",
    "env = Environment('tutorial-env')\n",
    "cd = CondaDependencies.create(pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1'])\n",
    "\n",
    "env.python.conda_dependencies = cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job\n",
    "\n",
    "The training takes about 15 mins with vm size comparable  to Standard_DS3_v2, `<MountPathOnTrainingPod>` is the same as the mountPath defined in mount-config.yaml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "nfs_folder = \"<MountPathOnTrainingPod>\" # training data are saved to <mountPoint> (have to use / as the path separator)\n",
    "\n",
    "args = ['--nfs-folder', nfs_folder]\n",
    "script_folder =  \"nfs_script\"\n",
    "src = ScriptRunConfig(source_directory=script_folder,\n",
    "                      script='test.py', \n",
    "                      arguments=args,\n",
    "                      compute_target=arcK_target,\n",
    "                      environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job\n",
    "\n",
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)  # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the job\n",
    "\n",
    "Go to the Azure Machine Learning Online Studio to verify the job status. \n",
    "\n",
    "* If it succeeded, in driver log, you will see the contents listed under the NFS mounting path in training pods (max number: 1000)\n",
    "* If it failed, you can judge the error message in experiment page, below shows an example if you give a **wrong** NFS mounting path. Please confirm the NFS mounting path based on your config map using [mount-config.yaml](https://github.com/Azure/AML-Kubernetes/blob/master/examples/train-using-nfs/amlarc-nfs-setup/mount-config.yaml). When you saw the error message, you can choose to cancel the NFS verify experiment to avoid more retries.\n",
    "\n",
    "![fishy](images/verify-nfs-training.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc402497f0168b24575e2ffafe64cd34c507b9a7fab971a93b09782ae565c5c6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
