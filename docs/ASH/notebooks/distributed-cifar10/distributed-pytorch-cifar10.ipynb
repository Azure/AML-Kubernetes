{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed PyTorch with DistributedDataParallel\n",
    "In this tutorial, you will train a PyTorch model on the [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset using distributed training with PyTorch's `DistributedDataParallel` module across a Azure Stack Hub CPU Kubernetes cluster. The training dataset are stored on Azure Machine Learning datastore backed up by Azure Stack Hub Storage account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "*     A Kubernetes cluster deployed on Azure Stack Hub, connected to Azure through ARC.\n",
    "     \n",
    "   For details on how to deploy kubernetes cluster on Azure Stack Hub and enabling ARC connection to Azure, please follow [this guide](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/AML-ARC-Compute.md)\n",
    "  \n",
    "\n",
    "*     Datastore setup in Azure Machine Learning workspace backed up by Azure Stack Hub storage account.\n",
    "\n",
    "   [This document](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/Train-AzureArc.md) is a detailed guide on how to create Azure Machine Learning workspace, create a  Azure Stack Hub Storage account, and setup datastore in AML workspace backed by ASH storage account.\n",
    "\n",
    "\n",
    "*      Last but not least, you need to be able to run a Notebook. \n",
    "\n",
    "   If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at [here](https://github.com/Azure/MachineLearningNotebooks) first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (azureml-telemetry 1.19.0 (c:\\users\\v-songshanli\\anaconda3\\envs\\pythonproject\\lib\\site-packages), Requirement.parse('azureml-telemetry~=1.18.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-telemetry 1.19.0 (c:\\users\\v-songshanli\\anaconda3\\envs\\pythonproject\\lib\\site-packages), Requirement.parse('azureml-telemetry~=1.18.0'), {'azureml-automl-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (azureml-core 1.19.0 (c:\\users\\v-songshanli\\anaconda3\\envs\\pythonproject\\lib\\site-packages), Requirement.parse('azureml-core~=1.18.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (azureml-core 1.19.0 (c:\\users\\v-songshanli\\anaconda3\\envs\\pythonproject\\lib\\site-packages), Requirement.parse('azureml-core~=1.18.0')).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (azureml-core 1.19.0 (c:\\users\\v-songshanli\\anaconda3\\envs\\pythonproject\\lib\\site-packages), Requirement.parse('azureml-core~=1.18.0')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.19.0\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`. \n",
    "\n",
    "If you haven't done already please go to `config.json` file and fill in your workspace information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: sl-ash2-mal\n",
      "Azure region: eastus\n",
      "Subscription id: 6b736da6-3246-44dd-a0b8-b5e95484633d\n",
      "Resource group: sl-ash2\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace,  ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "You may download cifar10 dataset from [cifar10-data](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). Create folder \"cifar10-data\" under working directory of this notebook, then  copy \"cifar-10-python.tar.gz\" to folder \"cifar10-data\". The following cell will upload \"cifar-10-python.tar.gz\" to datastore of the workspace, and finally registered as dataset in the workspace. \n",
    "\n",
    "Upload and dataset registration take about 3 mins.\n",
    "\n",
    "To set up datastore using an azure stack hub storage account, please refer to [Train_azure_arc](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/Train-AzureArc.md). To register the dataset manually, please refer to this [video](https://msit.microsoftstream.com/video/51f7a3ff-0400-b9eb-2703-f1eb38bc6232)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Datastore, Dataset\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "datastore_name = \"ashstore\"\n",
    "\n",
    "if dataset_name not  in ws.datasets:\n",
    "    datastore =  Datastore.get(ws, datastore_name)\n",
    "    \n",
    "    src_dir, target_path = 'cifar10-data', 'cifar10-data-ash' #assuming cifar-10-python.tar.gz is in folder cifar10-data\n",
    "    \n",
    "    # upload data from local to AML datastore:\n",
    "    datastore.upload(src_dir, target_path)\n",
    "\n",
    "    # register data uploaded as AML dataset:\n",
    "    datastore_paths = [(datastore, target_path)]\n",
    "    cifar_ds = Dataset.File.from_files(path=datastore_paths)\n",
    "    cifar_ds.register(ws, dataset_name, \"CIFAR-10 images from https://www.cs.toronto.edu/~kriz/cifar.html\")\n",
    "        \n",
    "dataset_ash = ws.datasets[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing ArcKubernetesCompute\n",
    "\n",
    "The attaching code here depends  python package azureml-contrib-k8s which current is in private preview. Install private preview branch of AzureML SDK by running following command (private preview):\n",
    "\n",
    "<pre>\n",
    "pip install --disable-pip-version-check --extra-index-url https://azuremlsdktestpypi.azureedge.net/azureml-contrib-k8s-preview/D58E86006C65 azureml-contrib-k8s\n",
    "</pre>\n",
    "\n",
    "Attaching ASH cluster the first time may take 7 minutes. It will be much faster after first attachment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "arc attach  success\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.core.compute.arckubernetescompute import ArcKubernetesCompute\n",
    "\n",
    "resource_id = \"/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourceGroups/AML-stack-val/providers/Microsoft.Kubernetes/connectedClusters/kub-orlando-Test\"\n",
    "\n",
    "attach_config = ArcKubernetesCompute.attach_configuration(\n",
    "    resource_id= resource_id,\n",
    ")\n",
    "\n",
    "try:\n",
    "    attach_name = \"peymanarc\"\n",
    "    arcK_target_result = ArcKubernetesCompute.attach(ws, attach_name, attach_config)\n",
    "    arcK_target_result.wait_for_completion(show_output=True)\n",
    "    print('arc attach  success')\n",
    "except ComputeTargetException as e:\n",
    "    print(e)\n",
    "    print('arc attach  failed')\n",
    "\n",
    "attach_name = \"nc6\"#\"ds3v2\" \n",
    "arcK_target = ws.compute_targets[attach_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job and Submit a run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-cifar-distr'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "pytorch_env = Environment.from_conda_specification(name = 'pytorch-1.6-cpu', file_path = 'pytorch-script/conda_dependencies.yml')\n",
    "\n",
    "# Specify a CPU base image\n",
    "pytorch_env.docker.enabled = True\n",
    "pytorch_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job: torch.distributed with GLOO backend\n",
    "\n",
    "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on.\n",
    "\n",
    "In order to run a distributed PyTorch job with **torch.distributed** using the GLOO backend, create a `PyTorchConfiguration` and pass it to the `distributed_job_config` parameter of the ScriptRunConfig constructor. Specify `communication_backend='Gloo'` in the PyTorchConfiguration. The below code will configure node_count = 2. These is the number of worker nodes. The number of  distributed jobs will be 3 if one master node is used.  GLOO backend which is recommended backend for communications between CPUs.\n",
    "\n",
    "Tthe script for distributed training of CIFAR10 is already provided for you at `pytorch-script/cifar_dist_main.py`. In practice, you should be able to take any custom PyTorch training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "With node_count=2, training for one epoch may take 20 mins with vm size comparable to Standard_DS3_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.core import Dataset\n",
    "import os\n",
    "\n",
    "dataset_ash = Dataset.get_by_name(ws, name=dataset_name)\n",
    "args = [\n",
    "        '--data-folder', dataset_ash.as_mount(),\n",
    "        '--dist-backend', 'gloo',\n",
    "       '--epochs', 1 #20\n",
    "           ]\n",
    "\n",
    "distributed_job_config=PyTorchConfiguration(communication_backend='Gloo', node_count=2) #configuring AML pytorch config\n",
    "\n",
    "project_folder = \"pytorch-script\"\n",
    "run_script = \"cifar_dist_main.py\"\n",
    "src = ScriptRunConfig(\n",
    "                     source_directory=project_folder,\n",
    "                      script=run_script,\n",
    "                      arguments=args,\n",
    "                      compute_target=arcK_target,\n",
    "                      environment=pytorch_env,\n",
    "                      distributed_job_config=distributed_job_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: pytorch-cifar-distr_1613442168_09fb2717\n",
      "Web View: https://ml.azure.com/experiments/pytorch-cifar-distr/runs/pytorch-cifar-distr_1613442168_09fb2717?wsid=/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourcegroups/sl-ash2/workspaces/sl-ash2-mal\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-02-16T02:26:25.867258] Entering job preparation.\n",
      "[2021-02-16T02:26:26.814648] Starting job preparation.\n",
      "[2021-02-16T02:26:26.814685] Extracting the control code.\n",
      "[2021-02-16T02:26:26.836668] fetching and extracting the control code on master node.\n",
      "[2021-02-16T02:26:26.836693] Starting extract_project.\n",
      "[2021-02-16T02:26:26.836728] Starting to extract zip file.\n",
      "[2021-02-16T02:26:27.798329] Finished extracting zip file.\n",
      "[2021-02-16T02:26:27.917262] Using urllib.request Python 3.0 or later\n",
      "[2021-02-16T02:26:27.917316] Start fetching snapshots.\n",
      "[2021-02-16T02:26:27.917353] Start fetching snapshot.\n",
      "[2021-02-16T02:26:27.917370] Retrieving project from snapshot: 2643c629-4cad-45c3-8810-e047e068e6f0\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 62\n",
      "[2021-02-16T02:26:28.216498] Finished fetching snapshot.\n",
      "[2021-02-16T02:26:28.216525] Finished fetching snapshots.\n",
      "[2021-02-16T02:26:28.216536] Finished extract_project.\n",
      "[2021-02-16T02:26:28.226156] Finished fetching and extracting the control code.\n",
      "[2021-02-16T02:26:28.231724] Start run_history_prep.\n",
      "[2021-02-16T02:26:28.415561] Job preparation is complete.\n",
      "[2021-02-16T02:26:28.415608] Entering Data Context Managers in Sidecar\n",
      "[2021-02-16T02:26:28.416273] Running Sidecar prep cmd...\n",
      "[2021-02-16T02:26:28.530918] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/mounts/workspaceblobstore/azureml/pytorch-cifar-distr_1613442168_09fb2717\n",
      "[2021-02-16T02:26:28.531646] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.21.0.post2 azureml-dataprep==2.9.1. Session id: 57022703-de7e-4f0b-a9ac-1e4f0cd0a51e. Run id: pytorch-cifar-distr_1613442168_09fb2717.\n",
      "Processing 'input__5a164dc5'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('ashstore', 'cifar10-data-ash')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"24d86baf-41f9-40e1-ae0d-5ae8b4c9cdfc\",\n",
      "    \"name\": \"cifar10\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"CIFAR-10 images from https://www.cs.toronto.edu/~kriz/cifar.html\",\n",
      "    \"workspace\": \"Workspace.create(name='sl-ash2-mal', subscription_id='6b736da6-3246-44dd-a0b8-b5e95484633d', resource_group='sl-ash2')\"\n",
      "  }\n",
      "}\n",
      "Mounting input__5a164dc5 to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju.\n",
      "Mounted input__5a164dc5 to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju as folder.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset input__5a164dc5's target path to /mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1\n",
      "[2021-02-16T02:33:16.940139] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-02-16T02:33:20.740265] Ran Sidecar prep cmd.\n",
      "[2021-02-16T02:33:20.740303] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log_0.txt\n",
      "==========================================\n",
      "\n",
      "bash: /azureml-envs/azureml_77ae6faafb422d20b955420f1d57d91e/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "[2021-02-16T02:34:55.228825] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['cifar_dist_main.py', '--data-folder', 'DatasetConsumptionConfig:input__5a164dc5', '--dist-backend', 'gloo', '--epochs', '1'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 108\n",
      "[2021-02-16T02:34:57.451493] Entering Run History Context Manager.\n",
      "[2021-02-16T02:34:58.258810] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/mounts/workspaceblobstore/azureml/pytorch-cifar-distr_1613442168_09fb2717\n",
      "[2021-02-16T02:34:58.259001] Preparing to call script [cifar_dist_main.py] with arguments:['--data-folder', '$input__5a164dc5', '--dist-backend', 'gloo', '--epochs', '1']\n",
      "[2021-02-16T02:34:58.259300] After variable expansion, calling script [cifar_dist_main.py] with arguments:['--data-folder', '/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju', '--dist-backend', 'gloo', '--epochs', '1']\n",
      "\n",
      "data fold /mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju\n",
      "rank=  0\n",
      "world_size=  2\n",
      "==> Preparing data..\n",
      "data_folder /mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju\n",
      "==> Building model..\n",
      "epoch 0\n",
      "\n",
      "Epoch: 0\n",
      "0 196 Loss: 2.327 | Acc: 2.344% (3/128)\n",
      "1 196 Loss: 2.302 | Acc: 9.766% (25/256)\n",
      "2 196 Loss: 2.274 | Acc: 12.240% (47/384)\n",
      "3 196 Loss: 2.279 | Acc: 12.109% (62/512)\n",
      "4 196 Loss: 2.252 | Acc: 12.969% (83/640)\n",
      "5 196 Loss: 2.238 | Acc: 14.193% (109/768)\n",
      "6 196 Loss: 2.215 | Acc: 16.071% (144/896)\n",
      "7 196 Loss: 2.184 | Acc: 16.797% (172/1024)\n",
      "8 196 Loss: 2.183 | Acc: 17.101% (197/1152)\n",
      "9 196 Loss: 2.170 | Acc: 18.281% (234/1280)\n",
      "10 196 Loss: 2.168 | Acc: 18.466% (260/1408)\n",
      "11 196 Loss: 2.167 | Acc: 18.685% (287/1536)\n",
      "12 196 Loss: 2.171 | Acc: 18.630% (310/1664)\n",
      "13 196 Loss: 2.170 | Acc: 19.141% (343/1792)\n",
      "14 196 Loss: 2.165 | Acc: 19.323% (371/1920)\n",
      "15 196 Loss: 2.160 | Acc: 19.141% (392/2048)\n",
      "16 196 Loss: 2.155 | Acc: 19.715% (429/2176)\n",
      "17 196 Loss: 2.148 | Acc: 20.052% (462/2304)\n",
      "18 196 Loss: 2.143 | Acc: 20.230% (492/2432)\n",
      "19 196 Loss: 2.135 | Acc: 20.547% (526/2560)\n",
      "20 196 Loss: 2.126 | Acc: 20.833% (560/2688)\n",
      "21 196 Loss: 2.127 | Acc: 20.632% (581/2816)\n",
      "22 196 Loss: 2.115 | Acc: 21.060% (620/2944)\n",
      "23 196 Loss: 2.115 | Acc: 21.159% (650/3072)\n",
      "24 196 Loss: 2.113 | Acc: 21.406% (685/3200)\n",
      "25 196 Loss: 2.108 | Acc: 21.695% (722/3328)\n",
      "26 196 Loss: 2.102 | Acc: 21.962% (759/3456)\n",
      "27 196 Loss: 2.099 | Acc: 22.154% (794/3584)\n",
      "28 196 Loss: 2.096 | Acc: 22.279% (827/3712)\n",
      "29 196 Loss: 2.091 | Acc: 22.240% (854/3840)\n",
      "30 196 Loss: 2.088 | Acc: 22.354% (887/3968)\n",
      "31 196 Loss: 2.082 | Acc: 22.510% (922/4096)\n",
      "32 196 Loss: 2.079 | Acc: 22.633% (956/4224)\n",
      "33 196 Loss: 2.076 | Acc: 22.725% (989/4352)\n",
      "34 196 Loss: 2.073 | Acc: 22.835% (1023/4480)\n",
      "35 196 Loss: 2.067 | Acc: 23.047% (1062/4608)\n",
      "36 196 Loss: 2.058 | Acc: 23.353% (1106/4736)\n",
      "37 196 Loss: 2.056 | Acc: 23.479% (1142/4864)\n",
      "38 196 Loss: 2.049 | Acc: 23.758% (1186/4992)\n",
      "39 196 Loss: 2.048 | Acc: 23.789% (1218/5120)\n",
      "40 196 Loss: 2.043 | Acc: 23.800% (1249/5248)\n",
      "41 196 Loss: 2.038 | Acc: 24.014% (1291/5376)\n",
      "42 196 Loss: 2.034 | Acc: 24.201% (1332/5504)\n",
      "43 196 Loss: 2.029 | Acc: 24.450% (1377/5632)\n",
      "44 196 Loss: 2.024 | Acc: 24.653% (1420/5760)\n",
      "45 196 Loss: 2.018 | Acc: 24.864% (1464/5888)\n",
      "46 196 Loss: 2.012 | Acc: 25.066% (1508/6016)\n",
      "47 196 Loss: 2.008 | Acc: 25.277% (1553/6144)\n",
      "48 196 Loss: 2.006 | Acc: 25.255% (1584/6272)\n",
      "49 196 Loss: 1.997 | Acc: 25.625% (1640/6400)\n",
      "50 196 Loss: 1.994 | Acc: 25.858% (1688/6528)\n",
      "51 196 Loss: 1.988 | Acc: 26.022% (1732/6656)\n",
      "52 196 Loss: 1.986 | Acc: 26.120% (1772/6784)\n",
      "53 196 Loss: 1.982 | Acc: 26.230% (1813/6912)\n",
      "54 196 Loss: 1.978 | Acc: 26.321% (1853/7040)\n",
      "55 196 Loss: 1.974 | Acc: 26.409% (1893/7168)\n",
      "56 196 Loss: 1.971 | Acc: 26.562% (1938/7296)\n",
      "57 196 Loss: 1.969 | Acc: 26.670% (1980/7424)\n",
      "58 196 Loss: 1.970 | Acc: 26.615% (2010/7552)\n",
      "59 196 Loss: 1.967 | Acc: 26.823% (2060/7680)\n",
      "60 196 Loss: 1.964 | Acc: 27.011% (2109/7808)\n",
      "61 196 Loss: 1.960 | Acc: 27.104% (2151/7936)\n",
      "62 196 Loss: 1.957 | Acc: 27.158% (2190/8064)\n",
      "63 196 Loss: 1.953 | Acc: 27.295% (2236/8192)\n",
      "64 196 Loss: 1.950 | Acc: 27.356% (2276/8320)\n",
      "65 196 Loss: 1.948 | Acc: 27.403% (2315/8448)\n",
      "66 196 Loss: 1.944 | Acc: 27.495% (2358/8576)\n",
      "67 196 Loss: 1.941 | Acc: 27.562% (2399/8704)\n",
      "68 196 Loss: 1.939 | Acc: 27.604% (2438/8832)\n",
      "69 196 Loss: 1.936 | Acc: 27.634% (2476/8960)\n",
      "70 196 Loss: 1.931 | Acc: 27.762% (2523/9088)\n",
      "71 196 Loss: 1.928 | Acc: 27.875% (2569/9216)\n",
      "72 196 Loss: 1.925 | Acc: 27.997% (2616/9344)\n",
      "73 196 Loss: 1.921 | Acc: 28.051% (2657/9472)\n",
      "74 196 Loss: 1.919 | Acc: 28.094% (2697/9600)\n",
      "75 196 Loss: 1.917 | Acc: 28.146% (2738/9728)\n",
      "76 196 Loss: 1.914 | Acc: 28.287% (2788/9856)\n",
      "77 196 Loss: 1.911 | Acc: 28.355% (2831/9984)\n",
      "78 196 Loss: 1.909 | Acc: 28.362% (2868/10112)\n",
      "79 196 Loss: 1.907 | Acc: 28.438% (2912/10240)\n",
      "80 196 Loss: 1.904 | Acc: 28.520% (2957/10368)\n",
      "81 196 Loss: 1.901 | Acc: 28.592% (3001/10496)\n",
      "82 196 Loss: 1.900 | Acc: 28.624% (3041/10624)\n",
      "83 196 Loss: 1.898 | Acc: 28.702% (3086/10752)\n",
      "84 196 Loss: 1.897 | Acc: 28.814% (3135/10880)\n",
      "85 196 Loss: 1.895 | Acc: 28.897% (3181/11008)\n",
      "86 196 Loss: 1.894 | Acc: 28.933% (3222/11136)\n",
      "87 196 Loss: 1.894 | Acc: 28.915% (3257/11264)\n",
      "88 196 Loss: 1.891 | Acc: 28.950% (3298/11392)\n",
      "89 196 Loss: 1.888 | Acc: 29.010% (3342/11520)\n",
      "90 196 Loss: 1.887 | Acc: 29.078% (3387/11648)\n",
      "91 196 Loss: 1.886 | Acc: 29.076% (3424/11776)\n",
      "92 196 Loss: 1.885 | Acc: 29.133% (3468/11904)\n",
      "93 196 Loss: 1.884 | Acc: 29.131% (3505/12032)\n",
      "94 196 Loss: 1.882 | Acc: 29.243% (3556/12160)\n",
      "95 196 Loss: 1.879 | Acc: 29.338% (3605/12288)\n",
      "96 196 Loss: 1.878 | Acc: 29.373% (3647/12416)\n",
      "97 196 Loss: 1.874 | Acc: 29.496% (3700/12544)\n",
      "98 196 Loss: 1.872 | Acc: 29.609% (3752/12672)\n",
      "99 196 Loss: 1.869 | Acc: 29.727% (3805/12800)\n",
      "100 196 Loss: 1.866 | Acc: 29.788% (3851/12928)\n",
      "101 196 Loss: 1.865 | Acc: 29.864% (3899/13056)\n",
      "102 196 Loss: 1.863 | Acc: 29.930% (3946/13184)\n",
      "103 196 Loss: 1.861 | Acc: 30.003% (3994/13312)\n",
      "104 196 Loss: 1.858 | Acc: 30.089% (4044/13440)\n",
      "105 196 Loss: 1.856 | Acc: 30.189% (4096/13568)\n",
      "106 196 Loss: 1.853 | Acc: 30.272% (4146/13696)\n",
      "107 196 Loss: 1.850 | Acc: 30.411% (4204/13824)\n",
      "108 196 Loss: 1.846 | Acc: 30.591% (4268/13952)\n",
      "109 196 Loss: 1.843 | Acc: 30.703% (4323/14080)\n",
      "110 196 Loss: 1.841 | Acc: 30.778% (4373/14208)\n",
      "111 196 Loss: 1.841 | Acc: 30.734% (4406/14336)\n",
      "112 196 Loss: 1.839 | Acc: 30.794% (4454/14464)\n",
      "113 196 Loss: 1.837 | Acc: 30.900% (4509/14592)\n",
      "114 196 Loss: 1.836 | Acc: 30.917% (4551/14720)\n",
      "115 196 Loss: 1.836 | Acc: 30.960% (4597/14848)\n",
      "116 196 Loss: 1.835 | Acc: 31.003% (4643/14976)\n",
      "117 196 Loss: 1.833 | Acc: 31.065% (4692/15104)\n",
      "118 196 Loss: 1.833 | Acc: 31.079% (4734/15232)\n",
      "119 196 Loss: 1.831 | Acc: 31.159% (4786/15360)\n",
      "120 196 Loss: 1.828 | Acc: 31.250% (4840/15488)\n",
      "121 196 Loss: 1.826 | Acc: 31.314% (4890/15616)\n",
      "122 196 Loss: 1.825 | Acc: 31.390% (4942/15744)\n",
      "123 196 Loss: 1.823 | Acc: 31.464% (4994/15872)\n",
      "124 196 Loss: 1.822 | Acc: 31.500% (5040/16000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 196 Loss: 1.820 | Acc: 31.554% (5089/16128)\n",
      "126 196 Loss: 1.818 | Acc: 31.613% (5139/16256)\n",
      "127 196 Loss: 1.818 | Acc: 31.659% (5187/16384)\n",
      "128 196 Loss: 1.816 | Acc: 31.783% (5248/16512)\n",
      "129 196 Loss: 1.815 | Acc: 31.839% (5298/16640)\n",
      "130 196 Loss: 1.814 | Acc: 31.870% (5344/16768)\n",
      "131 196 Loss: 1.812 | Acc: 31.919% (5393/16896)\n",
      "132 196 Loss: 1.809 | Acc: 31.984% (5445/17024)\n",
      "133 196 Loss: 1.807 | Acc: 32.014% (5491/17152)\n",
      "134 196 Loss: 1.805 | Acc: 32.089% (5545/17280)\n",
      "135 196 Loss: 1.803 | Acc: 32.181% (5602/17408)\n",
      "136 196 Loss: 1.802 | Acc: 32.294% (5663/17536)\n",
      "137 196 Loss: 1.801 | Acc: 32.343% (5713/17664)\n",
      "138 196 Loss: 1.798 | Acc: 32.464% (5776/17792)\n",
      "139 196 Loss: 1.796 | Acc: 32.545% (5832/17920)\n",
      "140 196 Loss: 1.795 | Acc: 32.602% (5884/18048)\n",
      "141 196 Loss: 1.793 | Acc: 32.647% (5934/18176)\n",
      "142 196 Loss: 1.791 | Acc: 32.709% (5987/18304)\n",
      "143 196 Loss: 1.790 | Acc: 32.775% (6041/18432)\n",
      "144 196 Loss: 1.789 | Acc: 32.829% (6093/18560)\n",
      "145 196 Loss: 1.786 | Acc: 32.914% (6151/18688)\n",
      "146 196 Loss: 1.784 | Acc: 32.999% (6209/18816)\n",
      "147 196 Loss: 1.782 | Acc: 33.076% (6266/18944)\n",
      "148 196 Loss: 1.783 | Acc: 33.111% (6315/19072)\n",
      "149 196 Loss: 1.782 | Acc: 33.141% (6363/19200)\n",
      "150 196 Loss: 1.780 | Acc: 33.263% (6429/19328)\n",
      "151 196 Loss: 1.779 | Acc: 33.326% (6484/19456)\n",
      "152 196 Loss: 1.777 | Acc: 33.430% (6547/19584)\n",
      "153 196 Loss: 1.777 | Acc: 33.452% (6594/19712)\n",
      "154 196 Loss: 1.776 | Acc: 33.533% (6653/19840)\n",
      "155 196 Loss: 1.774 | Acc: 33.619% (6713/19968)\n",
      "156 196 Loss: 1.772 | Acc: 33.713% (6775/20096)\n",
      "157 196 Loss: 1.771 | Acc: 33.752% (6826/20224)\n",
      "158 196 Loss: 1.770 | Acc: 33.825% (6884/20352)\n",
      "159 196 Loss: 1.769 | Acc: 33.872% (6937/20480)\n",
      "160 196 Loss: 1.768 | Acc: 33.924% (6991/20608)\n",
      "161 196 Loss: 1.766 | Acc: 33.970% (7044/20736)\n",
      "162 196 Loss: 1.765 | Acc: 34.059% (7106/20864)\n",
      "163 196 Loss: 1.763 | Acc: 34.142% (7167/20992)\n",
      "164 196 Loss: 1.763 | Acc: 34.148% (7212/21120)\n",
      "165 196 Loss: 1.762 | Acc: 34.191% (7265/21248)\n",
      "166 196 Loss: 1.761 | Acc: 34.239% (7319/21376)\n",
      "167 196 Loss: 1.760 | Acc: 34.263% (7368/21504)\n",
      "168 196 Loss: 1.758 | Acc: 34.287% (7417/21632)\n",
      "169 196 Loss: 1.756 | Acc: 34.352% (7475/21760)\n",
      "170 196 Loss: 1.756 | Acc: 34.375% (7524/21888)\n",
      "171 196 Loss: 1.754 | Acc: 34.430% (7580/22016)\n",
      "172 196 Loss: 1.752 | Acc: 34.479% (7635/22144)\n",
      "173 196 Loss: 1.750 | Acc: 34.550% (7695/22272)\n",
      "174 196 Loss: 1.749 | Acc: 34.621% (7755/22400)\n",
      "175 196 Loss: 1.749 | Acc: 34.646% (7805/22528)\n",
      "176 196 Loss: 1.748 | Acc: 34.693% (7860/22656)\n",
      "177 196 Loss: 1.747 | Acc: 34.752% (7918/22784)\n",
      "178 196 Loss: 1.746 | Acc: 34.807% (7975/22912)\n",
      "179 196 Loss: 1.744 | Acc: 34.865% (8033/23040)\n",
      "180 196 Loss: 1.743 | Acc: 34.897% (8085/23168)\n",
      "181 196 Loss: 1.742 | Acc: 34.985% (8150/23296)\n",
      "182 196 Loss: 1.740 | Acc: 35.062% (8213/23424)\n",
      "183 196 Loss: 1.739 | Acc: 35.169% (8283/23552)\n",
      "184 196 Loss: 1.739 | Acc: 35.177% (8330/23680)\n",
      "185 196 Loss: 1.738 | Acc: 35.186% (8377/23808)\n",
      "186 196 Loss: 1.738 | Acc: 35.219% (8430/23936)\n",
      "187 196 Loss: 1.736 | Acc: 35.260% (8485/24064)\n",
      "188 196 Loss: 1.736 | Acc: 35.284% (8536/24192)\n",
      "189 196 Loss: 1.735 | Acc: 35.321% (8590/24320)\n",
      "190 196 Loss: 1.733 | Acc: 35.381% (8650/24448)\n",
      "191 196 Loss: 1.732 | Acc: 35.400% (8700/24576)\n",
      "192 196 Loss: 1.732 | Acc: 35.456% (8759/24704)\n",
      "193 196 Loss: 1.731 | Acc: 35.499% (8815/24832)\n",
      "194 196 Loss: 1.731 | Acc: 35.521% (8866/24960)\n",
      "195 196 Loss: 1.729 | Acc: 35.544% (8886/25000)\n",
      "0 100 Loss: 1.509 | Acc: 47.000% (47/100)\n",
      "1 100 Loss: 1.530 | Acc: 46.000% (92/200)\n",
      "2 100 Loss: 1.540 | Acc: 43.667% (131/300)\n",
      "3 100 Loss: 1.524 | Acc: 43.500% (174/400)\n",
      "4 100 Loss: 1.559 | Acc: 42.000% (210/500)\n",
      "5 100 Loss: 1.570 | Acc: 41.000% (246/600)\n",
      "6 100 Loss: 1.590 | Acc: 40.857% (286/700)\n",
      "7 100 Loss: 1.586 | Acc: 41.500% (332/800)\n",
      "8 100 Loss: 1.576 | Acc: 41.667% (375/900)\n",
      "9 100 Loss: 1.555 | Acc: 42.800% (428/1000)\n",
      "10 100 Loss: 1.547 | Acc: 43.091% (474/1100)\n",
      "11 100 Loss: 1.540 | Acc: 43.500% (522/1200)\n",
      "12 100 Loss: 1.551 | Acc: 43.154% (561/1300)\n",
      "13 100 Loss: 1.557 | Acc: 42.786% (599/1400)\n",
      "14 100 Loss: 1.545 | Acc: 43.133% (647/1500)\n",
      "15 100 Loss: 1.549 | Acc: 43.062% (689/1600)\n",
      "16 100 Loss: 1.557 | Acc: 42.765% (727/1700)\n",
      "17 100 Loss: 1.549 | Acc: 42.722% (769/1800)\n",
      "18 100 Loss: 1.555 | Acc: 42.737% (812/1900)\n",
      "19 100 Loss: 1.563 | Acc: 42.550% (851/2000)\n",
      "20 100 Loss: 1.563 | Acc: 42.429% (891/2100)\n",
      "21 100 Loss: 1.559 | Acc: 42.773% (941/2200)\n",
      "22 100 Loss: 1.555 | Acc: 42.826% (985/2300)\n",
      "23 100 Loss: 1.552 | Acc: 42.958% (1031/2400)\n",
      "24 100 Loss: 1.549 | Acc: 43.160% (1079/2500)\n",
      "25 100 Loss: 1.559 | Acc: 42.769% (1112/2600)\n",
      "26 100 Loss: 1.557 | Acc: 42.926% (1159/2700)\n",
      "27 100 Loss: 1.557 | Acc: 42.857% (1200/2800)\n",
      "28 100 Loss: 1.562 | Acc: 42.621% (1236/2900)\n",
      "29 100 Loss: 1.562 | Acc: 42.433% (1273/3000)\n",
      "30 100 Loss: 1.560 | Acc: 42.516% (1318/3100)\n",
      "31 100 Loss: 1.557 | Acc: 42.562% (1362/3200)\n",
      "32 100 Loss: 1.562 | Acc: 42.242% (1394/3300)\n",
      "33 100 Loss: 1.565 | Acc: 42.235% (1436/3400)\n",
      "34 100 Loss: 1.565 | Acc: 42.086% (1473/3500)\n",
      "35 100 Loss: 1.563 | Acc: 42.278% (1522/3600)\n",
      "36 100 Loss: 1.564 | Acc: 42.108% (1558/3700)\n",
      "37 100 Loss: 1.562 | Acc: 42.263% (1606/3800)\n",
      "38 100 Loss: 1.560 | Acc: 42.359% (1652/3900)\n",
      "39 100 Loss: 1.562 | Acc: 42.200% (1688/4000)\n",
      "40 100 Loss: 1.561 | Acc: 42.220% (1731/4100)\n",
      "41 100 Loss: 1.562 | Acc: 42.214% (1773/4200)\n",
      "42 100 Loss: 1.560 | Acc: 42.395% (1823/4300)\n",
      "43 100 Loss: 1.558 | Acc: 42.409% (1866/4400)\n",
      "44 100 Loss: 1.555 | Acc: 42.400% (1908/4500)\n",
      "45 100 Loss: 1.559 | Acc: 42.283% (1945/4600)\n",
      "46 100 Loss: 1.555 | Acc: 42.404% (1993/4700)\n",
      "47 100 Loss: 1.554 | Acc: 42.458% (2038/4800)\n",
      "48 100 Loss: 1.551 | Acc: 42.551% (2085/4900)\n",
      "49 100 Loss: 1.550 | Acc: 42.580% (2129/5000)\n",
      "50 100 Loss: 1.550 | Acc: 42.667% (2176/5100)\n",
      "51 100 Loss: 1.551 | Acc: 42.635% (2217/5200)\n",
      "52 100 Loss: 1.550 | Acc: 42.566% (2256/5300)\n",
      "53 100 Loss: 1.552 | Acc: 42.593% (2300/5400)\n",
      "54 100 Loss: 1.555 | Acc: 42.400% (2332/5500)\n",
      "55 100 Loss: 1.559 | Acc: 42.161% (2361/5600)\n",
      "56 100 Loss: 1.560 | Acc: 42.123% (2401/5700)\n",
      "57 100 Loss: 1.556 | Acc: 42.276% (2452/5800)\n",
      "58 100 Loss: 1.561 | Acc: 42.085% (2483/5900)\n",
      "59 100 Loss: 1.563 | Acc: 41.933% (2516/6000)\n",
      "60 100 Loss: 1.564 | Acc: 41.852% (2553/6100)\n",
      "61 100 Loss: 1.564 | Acc: 41.806% (2592/6200)\n",
      "62 100 Loss: 1.566 | Acc: 41.794% (2633/6300)\n",
      "63 100 Loss: 1.565 | Acc: 41.875% (2680/6400)\n",
      "64 100 Loss: 1.565 | Acc: 41.862% (2721/6500)\n",
      "65 100 Loss: 1.565 | Acc: 41.879% (2764/6600)\n",
      "66 100 Loss: 1.566 | Acc: 41.836% (2803/6700)\n",
      "67 100 Loss: 1.567 | Acc: 41.838% (2845/6800)\n",
      "68 100 Loss: 1.568 | Acc: 41.739% (2880/6900)\n",
      "69 100 Loss: 1.569 | Acc: 41.614% (2913/7000)\n",
      "70 100 Loss: 1.570 | Acc: 41.535% (2949/7100)\n",
      "71 100 Loss: 1.570 | Acc: 41.569% (2993/7200)\n",
      "72 100 Loss: 1.571 | Acc: 41.521% (3031/7300)\n",
      "73 100 Loss: 1.569 | Acc: 41.527% (3073/7400)\n",
      "74 100 Loss: 1.569 | Acc: 41.547% (3116/7500)\n",
      "75 100 Loss: 1.569 | Acc: 41.605% (3162/7600)\n",
      "76 100 Loss: 1.568 | Acc: 41.519% (3197/7700)\n",
      "77 100 Loss: 1.569 | Acc: 41.513% (3238/7800)\n",
      "78 100 Loss: 1.567 | Acc: 41.608% (3287/7900)\n",
      "79 100 Loss: 1.568 | Acc: 41.562% (3325/8000)\n",
      "80 100 Loss: 1.568 | Acc: 41.617% (3371/8100)\n",
      "81 100 Loss: 1.570 | Acc: 41.512% (3404/8200)\n",
      "82 100 Loss: 1.571 | Acc: 41.518% (3446/8300)\n",
      "83 100 Loss: 1.572 | Acc: 41.476% (3484/8400)\n",
      "84 100 Loss: 1.573 | Acc: 41.482% (3526/8500)\n",
      "85 100 Loss: 1.572 | Acc: 41.558% (3574/8600)\n",
      "86 100 Loss: 1.574 | Acc: 41.448% (3606/8700)\n",
      "87 100 Loss: 1.574 | Acc: 41.443% (3647/8800)\n",
      "88 100 Loss: 1.574 | Acc: 41.506% (3694/8900)\n",
      "89 100 Loss: 1.574 | Acc: 41.467% (3732/9000)\n",
      "90 100 Loss: 1.573 | Acc: 41.451% (3772/9100)\n",
      "91 100 Loss: 1.574 | Acc: 41.457% (3814/9200)\n",
      "92 100 Loss: 1.573 | Acc: 41.441% (3854/9300)\n",
      "93 100 Loss: 1.573 | Acc: 41.447% (3896/9400)\n",
      "94 100 Loss: 1.573 | Acc: 41.495% (3942/9500)\n",
      "95 100 Loss: 1.573 | Acc: 41.479% (3982/9600)\n",
      "96 100 Loss: 1.572 | Acc: 41.515% (4027/9700)\n",
      "97 100 Loss: 1.572 | Acc: 41.510% (4068/9800)\n",
      "98 100 Loss: 1.572 | Acc: 41.515% (4110/9900)\n",
      "99 100 Loss: 1.573 | Acc: 41.460% (4146/10000)\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 108\n",
      "\n",
      "\n",
      "[2021-02-16T02:37:46.380437] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.054055213928222656 seconds\n",
      "[2021-02-16T02:37:46.751801] Finished context manager injector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-02-16T02:37:48.584051] Entering job release\n",
      "[2021-02-16T02:37:49.882145] Starting job release\n",
      "[2021-02-16T02:37:49.882642] Logging experiment finalizing status in history service.[2021-02-16T02:37:49.882786] job release stage : upload_datastore starting...\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 484\n",
      "[2021-02-16T02:37:49.883036] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-02-16T02:37:49.883257] job release stage : execute_job_release starting...[2021-02-16T02:37:49.883541] job release stage : copy_batchai_cached_logs starting...\n",
      "\n",
      "[2021-02-16T02:37:49.885432] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-02-16T02:37:49.936077] Entering context manager injector.\n",
      "[2021-02-16T02:37:49.977103] job release stage : upload_datastore completed...\n",
      "[2021-02-16T02:37:50.269284] job release stage : execute_job_release completed...\n",
      "[2021-02-16T02:37:50.683540] job release stage : send_run_telemetry starting...\n",
      "[2021-02-16T02:37:50.875880] get vm size and vm region successfully.\n",
      "[2021-02-16T02:37:50.888966] get compute meta data successfully.\n",
      "[2021-02-16T02:37:51.134108] post artifact meta request successfully.\n",
      "[2021-02-16T02:37:51.164845] upload compute record artifact successfully.\n",
      "[2021-02-16T02:37:51.373972] job release stage : send_run_telemetry completed...\n",
      "[2021-02-16T02:37:51.374151] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-02-16T02:37:51.374224] Running Sidecar release cmd...\n",
      "[2021-02-16T02:37:51.383707] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/mounts/workspaceblobstore/azureml/pytorch-cifar-distr_1613442168_09fb2717\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/pytorch-cifar-distr_1613442168_09fb2717/wd/tmpgg9v67ju.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-02-16T02:37:51.503938] Removing absolute paths from host...\n",
      "[2021-02-16T02:37:51.645851] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-02-16T02:37:52.062288] Ran Sidecar release cmd.\n",
      "[2021-02-16T02:37:52.062331] Job release is complete\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: pytorch-cifar-distr_1613442168_09fb2717\n",
      "Web View: https://ml.azure.com/experiments/pytorch-cifar-distr/runs/pytorch-cifar-distr_1613442168_09fb2717?wsid=/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourcegroups/sl-ash2/workspaces/sl-ash2-mal\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'pytorch-cifar-distr_1613442168_09fb2717',\n",
       " 'target': 'nc6',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-02-16T02:25:52.395478Z',\n",
       " 'endTimeUtc': '2021-02-16T02:38:09.719482Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'decc257a-e2e9-4923-97a5-b12fed3fa395',\n",
       "  'azureml.git.repository_uri': 'git@github.com:lisongshan007/AML-Kubernetes.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:lisongshan007/AML-Kubernetes.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'e2bca45811ab76c19bc777642ccf7f12fecd9162',\n",
       "  'mlflow.source.git.commit': 'e2bca45811ab76c19bc777642ccf7f12fecd9162',\n",
       "  'azureml.git.dirty': 'False',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '24d86baf-41f9-40e1-ae0d-5ae8b4c9cdfc'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__5a164dc5', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'cifar_dist_main.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data-folder',\n",
       "   'DatasetConsumptionConfig:input__5a164dc5',\n",
       "   '--dist-backend',\n",
       "   'gloo',\n",
       "   '--epochs',\n",
       "   '1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'PyTorch',\n",
       "  'communicator': 'Gloo',\n",
       "  'target': 'nc6',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__5a164dc5': {'dataLocation': {'dataset': {'id': '24d86baf-41f9-40e1-ae0d-5ae8b4c9cdfc',\n",
       "      'name': 'cifar10',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__5a164dc5',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 2,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'pytorch-1.6-cpu',\n",
       "   'version': 'Autosave_2020-12-10T03:47:24Z_55cb9ba6',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'torch==1.6.0',\n",
       "        'torchvision==0.7.0',\n",
       "        'future==0.17.1']}],\n",
       "     'name': 'azureml_77ae6faafb422d20b955420f1d57d91e'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': None, 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/55_azureml-execution-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt?sv=2019-02-02&sr=b&sig=zbm8HrguptW%2BlYp9EPoD%2B7AQBPMRtskM%2BtKml4njK7Y%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/55_azureml-execution-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt?sv=2019-02-02&sr=b&sig=x0WD0Ev3lOdY1KDc3pXB%2B58FWvwokQBde9qNC3J0ZuU%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/65_job_prep-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt?sv=2019-02-02&sr=b&sig=DVzNRlqCOgvpEQAuYduqwedtDJr8VXR0WrIc66ib4%2B8%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/65_job_prep-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt?sv=2019-02-02&sr=b&sig=3j0MwF0NP%2FQKDk4Ybg7G%2F2yc4rT%2Fdn0aEggwWBsOQx8%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_0.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=SDbwZvD2aycb19y0zhizIJnCLgrRSCiYxSgh5Yjokpg%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_1.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=aKBuRrWqFGyuZxnLEfO6jK2p51zDD2ZWnkGR94%2BZT3s%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/75_job_post-tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d.txt?sv=2019-02-02&sr=b&sig=jGEhPyh0Otgc4j9gZ8R5hswk7mZ7WihCfWj5TiUnwPg%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/75_job_post-tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d.txt?sv=2019-02-02&sr=b&sig=UO5%2FL%2BAVq757KU0r6H9bi4AtW9DUVimeb9cEBMK3aKU%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=O3XaZcEeXXWC%2FlZPrr2Qp4vLaqEzSRVs8cyHJUre6lY%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Fz%2BVwxYSwATry73ScVZ6aFmpC%2FcCamsanM15orL1v5k%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/0_108_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/0_108_azureml.log?sv=2019-02-02&sr=b&sig=pLSxm3ffC5UU19B4al2vQxwkhocPtPfy8jTqlQve3LY%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/1_88_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/1_88_azureml.log?sv=2019-02-02&sr=b&sig=lmR3NiObpB56cpzRzzHzwACtons9xZfwMSpiMl8UUOQ%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=Gfps4TQoReu9u7tZ%2BSBfT3GAkNRFupHf1pcqUqtEJOk%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=rZPfRGo8jswRK3SZ3IpxKfaJTCY4jtf%2FXFaEv4gmWaE%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=IPQOw%2FDuKxh3FQGZu4c%2Fm3jW%2FTUkGRO409N%2BqymIgWU%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=A0BMgHK4g%2BClgyDZfaQMFKWaBz41aCGfxkQyyNHJAeY%3D&st=2021-02-16T02%3A28%3A54Z&se=2021-02-16T10%3A38%3A54Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/all.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/all.log?sv=2019-02-02&sr=b&sig=55TZoINHBV8Rfj%2BF6%2BRdFd3HL12Bk64xNeVGEwoVyG4%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/task.enter_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=x%2BphsvYvopj2v2N2KmBuOHfL9gjS1F5lJU9UmZYBoUM%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/task.exit_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_4984b88dd9855bc51a7c2dc4ec9b8fb975e1f2535330a25170316224556bd189_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=HGHwT4loqwlWzhhUi5zXQc3JTKzT97IWi0uy8Eyhf3I%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/all.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/all.log?sv=2019-02-02&sr=b&sig=401q8m0BMYbrgEkEiWXTuOSY68pApmBH4joInXMZzGs%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/task.enter_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=DrZgIbMTa5pH5j2O2i5BDG4fo335Axxta6AwJcJZWDg%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/task.exit_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-cifar-distr_1613442168_09fb2717/logs/azureml/sidecar/tvmps_dcecc5008d5044d5efffe078d2511a7f3412cf11454b44ba8e2ff300047305fe_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=V%2B2gudwvai8DYTVoLcmEVyewYa71WgijVTUM7qgoDC8%3D&st=2021-02-16T02%3A28%3A55Z&se=2021-02-16T10%3A38%3A55Z&sp=r'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(src)\n",
    "run.wait_for_completion(show_output=True) # this provides a verbose log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the model\n",
    "register_model_name = 'cifar10torch'\n",
    "model = run.register_model(model_name=register_model_name, model_path='outputs/cifar10torch.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model named \"cifar10torch\" should be registered in your AML workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Registered Model\n",
    "\n",
    "To test the trained model, you can create (or use existing) a AKS cluster for serving the model using AML deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment, Workspace, Model, ComputeTarget\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using compute target:  aks-service-2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'aks-service-2'\n",
    "\n",
    "if aks_name not in  ws.compute_targets:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws,\n",
    "                                    name = aks_name,\n",
    "                                    provisioning_configuration = prov_config)\n",
    "    is_new_compute  = True\n",
    "\n",
    "    if aks_target.get_status() != \"Succeeded\":\n",
    "        aks_target.wait_for_completion(show_output=True)\n",
    "else:  \n",
    "    aks_target =  ws.compute_targets[aks_name]   \n",
    "    is_new_compute  = False\n",
    "    \n",
    "print(\"using compute target: \", aks_target.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running........\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(name='pytorch-cifar', file_path='pytorch-script/conda_dependencies.yml')\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score_pytorch.py', environment=env)\n",
    "deploy_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "#register_model_name = \"cifar10torch80\"\n",
    "model = ws.models[register_model_name]\n",
    "service_name = 'cifartorchservice4'\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=deploy_config,\n",
    "                       deployment_target=aks_target,\n",
    "                       overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Inputs:\n",
    "\n",
    "For testing purpose, first five images from test batch are extracted. Let's take a look these pictures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_files = [\"test_img_0_cat.jpg\", \"test_img_1_ship.jpg\",\"test_img_2_ship.jpg\",\"test_img_3_plane.jpg\",\"test_img_4_frog.jpg\"]\n",
    "\n",
    "for img_file in img_files:\n",
    "    image = Image.open(\"test_imgs/{}\".format(img_file))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some data process, these five images are converted to json as input for the trained model. The outputs are logits for each class per image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5160019397735596, -1.2456295490264893, 1.6823105812072754, 0.6995013356208801, 0.8892011046409607, 0.47988930344581604, 1.4375267028808594, -0.47753068804740906, -1.1731479167938232, -1.5666691064834595], [5.023127555847168, 5.144172668457031, -0.8311423063278198, -3.577611207962036, -2.236011505126953, -5.63224983215332, -3.499835729598999, -2.228290557861328, 5.397491455078125, 2.4311327934265137], [3.812830686569214, 2.7654457092285156, -0.23190726339817047, -2.1370229721069336, -1.7254106998443604, -4.214117050170898, -2.6311137676239014, -2.1098084449768066, 5.139931678771973, 1.676523208618164], [3.4747440814971924, 2.662689685821533, 0.07015886902809143, -1.692741870880127, -1.5648386478424072, -3.8260350227355957, -2.626882553100586, -1.4485933780670166, 4.246033191680908, 1.0078842639923096], [-1.1009407043457031, -1.784458875656128, 2.548421859741211, 0.21697556972503662, 2.352715492248535, -0.056166648864746094, 3.779412269592285, -0.6903271675109863, -3.0946576595306396, -1.8307464122772217]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cifar_test_input_pytorch.json\", \"r\") as fp:\n",
    "    inputs_json = json.load(fp)\n",
    "    \n",
    "inputs = json.dumps(inputs_json)\n",
    "resp = service.run(inputs)\n",
    "predicts = resp[\"predicts\"]\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can easily get the predictions of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bird', 'ship', 'ship', 'ship', 'frog']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "np_predicts = np.array(predicts)\n",
    "pred_indexes = np.argmax(np_predicts, 1)\n",
    "\n",
    "predict_labels = [classes[i] for i in pred_indexes]\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the newly created cluster\n",
    "\n",
    "Note: This is important if you wish to avoid the cost of this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_new_compute:\n",
    "    aks_target.delete()\n",
    "    service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Learn how to [download model then upload to Azure Storage blobs](../AML-model-download-upload.ipynb)\n",
    "2. Learn how to [inference using KFServing with model in Azure Storage Blobs](https://aka.ms/kfas)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "ninhu"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "MNIST"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "PyTorch"
  ],
  "friendly_name": "Distributed training with PyTorch",
  "index_order": 1,
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "pythonproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "tags": [
   "None"
  ],
  "task": "Train a model using distributed training via Nccl/Gloo"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
