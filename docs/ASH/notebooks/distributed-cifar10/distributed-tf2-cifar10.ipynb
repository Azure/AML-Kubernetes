{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Tensorflow 2 with MultiWorkerMirroredStrategy\n",
    "In this tutorial, you will train a PyTorch model on the [CIFAR10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset using distributed training with Tensorflow 2 `MultiWorkerMirroredStrategy` module across a Azure Stack Hub CPU Kubernetes cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prerequisite\n",
    "\n",
    "*     A Kubernetes cluster deployed on Azure Stack Hub, connected to Azure through ARC.\n",
    "     \n",
    "   For details on how to deploy kubernetes cluster on Azure Stack Hub and enabling ARC connection to Azure, please follow [this guide](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/AML-ARC-Compute.md)\n",
    "  \n",
    "\n",
    "*     Datastore setup in Azure Machine Learning workspace backed up by Azure Stack Hub storage account.\n",
    "\n",
    "   [This document](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/Train-AzureArc.md) is a detailed guide on how to create Azure Machine Learning workspace, create a  Azure Stack Hub Storage account, and setup datastore in AML workspace backed by ASH storage account.\n",
    "\n",
    "\n",
    "*      Last but not least, you need to be able to run a Notebook. \n",
    "\n",
    "   If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, make sure you go through the configuration Notebook located at [here](https://github.com/Azure/MachineLearningNotebooks) first if you haven't. This sets you up with a working config file that has information on your workspace, subscription id, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1606750503644
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Dataset, Environment, Experiment, Workspace\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`. \n",
    "\n",
    "If you haven't done already please go to `config.json` file and fill in your workspace information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1606750507604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: sl-ash2-mal\n",
      "Azure region: eastus\n",
      "Subscription id: 6b736da6-3246-44dd-a0b8-b5e95484633d\n",
      "Resource group: sl-ash2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Prepare dataset\n",
    "\n",
    "You may download cifar10 dataset from [cifar10-data](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz). Create folder \"cifar10-data\" under working directory of this notebook, then  copy \"cifar-10-python.tar.gz\" to folder \"cifar10-data\". The following cell will upload \"cifar-10-python.tar.gz\" to datastore of the workspace, and finally registered as dataset in the workspace. \n",
    "\n",
    "Upload and dataset registration take about 3 mins.\n",
    "\n",
    "To set up datastore using an azure stack hub storage account, please refer to [Train_azure_arc](https://github.com/Azure/AML-Kubernetes/blob/master/docs/ASH/Train-AzureArc.md). To register the dataset manually, please refer to this [video](https://msit.microsoftstream.com/video/51f7a3ff-0400-b9eb-2703-f1eb38bc6232)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1606064437587
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Datastore, Dataset\n",
    "\n",
    "dataset_name = 'cifar10'\n",
    "datastore_name = \"ashstore\"\n",
    "\n",
    "if dataset_name not  in ws.datasets:\n",
    "    datastore =  Datastore.get(ws, datastore_name)\n",
    "    \n",
    "    src_dir, target_path = 'cifar10-data', 'cifar10-data-ash' #assuming cifar-10-python.tar.gz is in folder cifar10-data\n",
    "    \n",
    "    # upload data from local to AML datastore:\n",
    "    datastore.upload(src_dir, target_path)\n",
    "\n",
    "    # register data uploaded as AML dataset:\n",
    "    datastore_paths = [(datastore, target_path)]\n",
    "    cifar_ds = Dataset.File.from_files(path=datastore_paths)\n",
    "    cifar_ds.register(ws, dataset_name, \"CIFAR-10 images from https://www.cs.toronto.edu/~kriz/cifar.html\")\n",
    "        \n",
    "dataset_ash = ws.datasets[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Create or attach existing ArcKubernetesCompute\n",
    "\n",
    "The attaching code here depends  python package azureml-contrib-k8s which current is in private preview. Install private preview branch of AzureML SDK by running following command (private preview):\n",
    "\n",
    "<pre>\n",
    "pip install --disable-pip-version-check --extra-index-url https://azuremlsdktestpypi.azureedge.net/azureml-contrib-k8s-preview/D58E86006C65 azureml-contrib-k8s\n",
    "</pre>\n",
    "\n",
    "\n",
    "Attaching ASH cluster the first time may take 7 minutes. It will be much faster after first attachment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1606662223344
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "arc attach  success\n"
     ]
    }
   ],
   "source": [
    "from azureml.contrib.core.compute.arckubernetescompute import ArcKubernetesCompute\n",
    "from azureml.core import ComputeTarget\n",
    "\n",
    "resource_id = \"/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourceGroups/sl-ash2/providers/Microsoft.Kubernetes/connectedClusters/sl-d2-o-arc\"\n",
    "\n",
    "attach_config = ArcKubernetesCompute.attach_configuration(\n",
    "    resource_id= resource_id,\n",
    ")\n",
    "\n",
    "try:\n",
    "    attach_name = \"sl-d2-o-arc\"\n",
    "    arcK_target_result = ArcKubernetesCompute.attach(ws, attach_name, attach_config)\n",
    "    arcK_target_result.wait_for_completion(show_output=True)\n",
    "    print('arc attach  success')\n",
    "except ComputeTargetException as e:\n",
    "    print(e)\n",
    "    print('arc attach  failed')\n",
    "\n",
    "attach_name = \"d13\"\n",
    "arcK_target = ComputeTarget(ws, attach_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Configure the training job and Submit a run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'dist-tf2-on-aks-arc'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_dockerfile(\n",
    "    name='tf_2.4',\n",
    "    dockerfile='tf-script/Dockerfile.gpu',\n",
    "    conda_specification='tf-script/tf-24-env.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job\n",
    "\n",
    "Use TensorflowConfiguration to set number of worker and number of parameter server to use.\n",
    "With worker_count= 3, training for one epoch may take 21 mins with vm size comparable to Standard_DS3_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1606750522680
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig, Run\n",
    "from azureml.core.runconfig import TensorflowConfiguration\n",
    "\n",
    "worker_count= 3\n",
    "src = ScriptRunConfig(source_directory='tf-script',\n",
    "                      script='train.py',\n",
    "                      arguments=[\n",
    "                          '--dataset-path', dataset_ash.as_mount(),\n",
    "                          '--epochs', 2,#80\n",
    "                          '--global-batch-size', 256,\n",
    "                          '--batches-per-epoch', 256,\n",
    "                          '--alpha-init', 0.005,\n",
    "                      ],\n",
    "                      compute_target=arcK_target,\n",
    "                      environment=env,\n",
    "                      distributed_job_config=TensorflowConfiguration(worker_count=worker_count, parameter_server_count=1))#configuring AML TF config\n",
    "\n",
    "rs_config = src.run_config.amlk8scompute.resource_configuration\n",
    "rs_config.gpu_count = 0\n",
    "rs_config.cpu_count = worker_count - rs_config.gpu_count\n",
    "rs_config.memory_request_in_gb = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your ScriptRunConfig object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: dist-tf2-on-aks-arc_1613702443_c5157ce0\n",
      "Web View: https://ml.azure.com/experiments/dist-tf2-on-aks-arc/runs/dist-tf2-on-aks-arc_1613702443_c5157ce0?wsid=/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourcegroups/sl-ash2/workspaces/sl-ash2-mal\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt\n",
      "========================================================================================================================\n",
      "\n",
      "2021-02-19T02:41:04Z Starting output-watcher...\n",
      "2021-02-19T02:41:04Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5\n",
      "Digest: sha256:68ffd55d5df309a0bda6ab9bb4fe2c3a1739a44786f2902f8f3bd785a61b3e4c\n",
      "Status: Image is up to date for viennaglobal.azurecr.io/azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_2a916f4728727b3b5b18dbee7e16a3e5:latest\n",
      "2021-02-19T02:41:06Z Check if container dist-tf2-on-aks-arc_1613702443_c5157ce0 already exist exited with 0, \n",
      "\n",
      "3ae3378a12604424d3d4f7492236b8e3c4c5bc953ecb0b566f06521173b70234\n",
      "2021/02/19 02:41:07 Starting App Insight Logger for task:  containerSetup\n",
      "2021/02/19 02:41:07 Version: 3.0.01509.0006 Branch: .SourceBranch Commit: e7e10a3\n",
      "2021/02/19 02:41:07 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/02/19 02:41:07 Starting infiniband setup\n",
      "2021/02/19 02:41:07 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/19 02:41:07 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/02/19 02:41:07 sshd inside container not required for job, skipping setup.\n",
      "2021/02/19 02:41:08 All App Insights Logs was send successfully\n",
      "2021-02-19T02:41:08Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-02-19T02:41:10.338171] Entering job preparation.\n",
      "[2021-02-19T02:41:10.955085] Starting job preparation.\n",
      "[2021-02-19T02:41:10.955121] Extracting the control code.\n",
      "[2021-02-19T02:41:10.962995] Finished fetching and extracting the control code.\n",
      "[2021-02-19T02:41:10.963062] Not a master node. Skipping rest of the context managers.\n",
      "[2021-02-19T02:41:10.963073] Entering Data Context Managers in Sidecar\n",
      "[2021-02-19T02:41:10.963518] Running Sidecar prep cmd...\n",
      "[2021-02-19T02:41:11.013559] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/mounts/workspaceblobstore/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0\n",
      "[2021-02-19T02:41:11.014529] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\"]}\n",
      "\n",
      "Streaming azureml-logs/70_driver_log-ps-0.txt\n",
      "=============================================\n",
      "\n",
      "[2021-02-19T02:49:00.104098] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError', 'UserExceptions:context_managers.UserExceptions'], invocation=['train.py', '--dataset-path', 'DatasetConsumptionConfig:input__358e1d54', '--epochs', '2', '--global-batch-size', '256', '--batches-per-epoch', '256', '--alpha-init', '0.005'])\n",
      "TF_CONFIG:\n",
      "{\n",
      "    \"cluster\": {\n",
      "        \"ps\": [\n",
      "            \"10.0.0.7:2222\"\n",
      "        ],\n",
      "        \"worker\": [\n",
      "            \"10.0.0.7:2223\",\n",
      "            \"10.0.0.8:2222\",\n",
      "            \"10.0.0.10:2222\"\n",
      "        ]\n",
      "    },\n",
      "    \"task\": {\n",
      "        \"type\": \"ps\",\n",
      "        \"index\": 0\n",
      "    },\n",
      "    \"environment\": \"cloud\"\n",
      "}\n",
      "This is a TensorFlow job. Job Name:ps Task index:0.\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 366\n",
      "[2021-02-19T02:49:02.369999] Entering Run History Context Manager.\n",
      "[2021-02-19T02:49:03.145872] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/mounts/workspaceblobstore/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0\n",
      "[2021-02-19T02:49:03.146184] Preparing to call script [train.py] with arguments:['--dataset-path', '$input__358e1d54', '--epochs', '2', '--global-batch-size', '256', '--batches-per-epoch', '256', '--alpha-init', '0.005']\n",
      "[2021-02-19T02:49:03.146279] After variable expansion, calling script [train.py] with arguments:['--dataset-path', '/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/wd/tmpxedmnahj', '--epochs', '2', '--global-batch-size', '256', '--batches-per-epoch', '256', '--alpha-init', '0.005']\n",
      "\n",
      "2021-02-19 02:49:03.396598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "worker 3 (4 total workers)\n",
      "2021-02-19 02:49:14.531638: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-19 02:49:14.532102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-02-19 02:49:14.532181: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: UNKNOWN ERROR (-1)\n",
      "2021-02-19 02:49:14.532291: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (65e1671209fa4b1dbbf7d096158298eb000003): /proc/driver/nvidia/version does not exist\n",
      "2021-02-19 02:49:14.532890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-02-19 02:49:14.533625: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-19 02:49:14.534634: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-02-19 02:49:14.546128: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job ps -> {0 -> 10.0.0.7:2222}\n",
      "2021-02-19 02:49:14.546254: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.7:2223, 1 -> 10.0.0.8:2222, 2 -> 10.0.0.10:2222, 3 -> 10.0.0.7:2222}\n",
      "2021-02-19 02:49:14.547019: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://10.0.0.7:2222\n",
      "has_gpu False\n",
      "calling model.fit ()\n",
      "2021-02-19 02:49:36.330378: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-02-19 02:49:36.332633: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2294680000 Hz\n",
      "Epoch 1/2\n",
      "epoch begin 0\n",
      "batch begin 0\n",
      "batch end 0\n",
      "batch begin 1\n",
      "batch end 1\n",
      "batch begin 2\n",
      "batch end 2\n",
      "batch begin 3\n",
      "batch end 3\n",
      "batch begin 4\n",
      "batch end 4\n",
      "batch begin 5\n",
      "batch end 5\n",
      "batch begin 6\n",
      "batch end 6\n",
      "batch begin 7\n",
      "batch end 7\n",
      "batch begin 8\n",
      "batch end 8\n",
      "batch begin 9\n",
      "batch end 9\n",
      "batch begin 10\n",
      "batch end 10\n",
      "batch begin 11\n",
      "batch end 11\n",
      "batch begin 12\n",
      "batch end 12\n",
      "batch begin 13\n",
      "batch end 13\n",
      "batch begin 14\n",
      "batch end 14\n",
      "batch begin 15\n",
      "batch end 15\n",
      "batch begin 16\n",
      "batch end 16\n",
      "batch begin 17\n",
      "batch end 17\n",
      "batch begin 18\n",
      "batch end 18\n",
      "batch begin 19\n",
      "batch end 19\n",
      "batch begin 20\n",
      "batch end 20\n",
      "batch begin 21\n",
      "batch end 21\n",
      "batch begin 22\n",
      "batch end 22\n",
      "batch begin 23\n",
      "batch end 23\n",
      "batch begin 24\n",
      "batch end 24\n",
      "batch begin 25\n",
      "batch end 25\n",
      "batch begin 26\n",
      "batch end 26\n",
      "batch begin 27\n",
      "batch end 27\n",
      "batch begin 28\n",
      "batch end 28\n",
      "batch begin 29\n",
      "batch end 29\n",
      "batch begin 30\n",
      "batch end 30\n",
      "batch begin 31\n",
      "batch end 31\n",
      "batch begin 32\n",
      "batch end 32\n",
      "batch begin 33\n",
      "batch end 33\n",
      "batch begin 34\n",
      "batch end 34\n",
      "batch begin 35\n",
      "batch end 35\n",
      "batch begin 36\n",
      "batch end 36\n",
      "batch begin 37\n",
      "batch end 37\n",
      "batch begin 38\n",
      "batch end 38\n",
      "batch begin 39\n",
      "batch end 39\n",
      "batch begin 40\n",
      "batch end 40\n",
      "batch begin 41\n",
      "batch end 41\n",
      "batch begin 42\n",
      "batch end 42\n",
      "batch begin 43\n",
      "batch end 43\n",
      "batch begin 44\n",
      "batch end 44\n",
      "batch begin 45\n",
      "batch end 45\n",
      "batch begin 46\n",
      "batch end 46\n",
      "batch begin 47\n",
      "batch end 47\n",
      "batch begin 48\n",
      "batch end 48\n",
      "batch begin 49\n",
      "batch end 49\n",
      "batch begin 50\n",
      "batch end 50\n",
      "batch begin 51\n",
      "batch end 51\n",
      "batch begin 52\n",
      "batch end 52\n",
      "batch begin 53\n",
      "batch end 53\n",
      "batch begin 54\n",
      "batch end 54\n",
      "batch begin 55\n",
      "batch end 55\n",
      "batch begin 56\n",
      "batch end 56\n",
      "batch begin 57\n",
      "batch end 57\n",
      "batch begin 58\n",
      "batch end 58\n",
      "batch begin 59\n",
      "batch end 59\n",
      "batch begin 60\n",
      "batch end 60\n",
      "batch begin 61\n",
      "batch end 61\n",
      "batch begin 62\n",
      "batch end 62\n",
      "batch begin 63\n",
      "batch end 63\n",
      "batch begin 64\n",
      "batch end 64\n",
      "batch begin 65\n",
      "batch end 65\n",
      "batch begin 66\n",
      "batch end 66\n",
      "batch begin 67\n",
      "batch end 67\n",
      "batch begin 68\n",
      "batch end 68\n",
      "batch begin 69\n",
      "batch end 69\n",
      "batch begin 70\n",
      "batch end 70\n",
      "batch begin 71\n",
      "batch end 71\n",
      "batch begin 72\n",
      "batch end 72\n",
      "batch begin 73\n",
      "batch end 73\n",
      "batch begin 74\n",
      "batch end 74\n",
      "batch begin 75\n",
      "batch end 75\n",
      "batch begin 76\n",
      "batch end 76\n",
      "batch begin 77\n",
      "batch end 77\n",
      "batch begin 78\n",
      "batch end 78\n",
      "batch begin 79\n",
      "batch end 79\n",
      "batch begin 80\n",
      "batch end 80\n",
      "batch begin 81\n",
      "batch end 81\n",
      "batch begin 82\n",
      "batch end 82\n",
      "batch begin 83\n",
      "batch end 83\n",
      "batch begin 84\n",
      "batch end 84\n",
      "batch begin 85\n",
      "batch end 85\n",
      "batch begin 86\n",
      "batch end 86\n",
      "batch begin 87\n",
      "batch end 87\n",
      "batch begin 88\n",
      "batch end 88\n",
      "batch begin 89\n",
      "batch end 89\n",
      "batch begin 90\n",
      "batch end 90\n",
      "batch begin 91\n",
      "batch end 91\n",
      "batch begin 92\n",
      "batch end 92\n",
      "batch begin 93\n",
      "batch end 93\n",
      "batch begin 94\n",
      "batch end 94\n",
      "batch begin 95\n",
      "batch end 95\n",
      "batch begin 96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch end 96\n",
      "batch begin 97\n",
      "batch end 97\n",
      "batch begin 98\n",
      "batch end 98\n",
      "batch begin 99\n",
      "batch end 99\n",
      "batch begin 100\n",
      "batch end 100\n",
      "batch begin 101\n",
      "batch end 101\n",
      "batch begin 102\n",
      "batch end 102\n",
      "batch begin 103\n",
      "batch end 103\n",
      "batch begin 104\n",
      "batch end 104\n",
      "batch begin 105\n",
      "batch end 105\n",
      "batch begin 106\n",
      "batch end 106\n",
      "batch begin 107\n",
      "batch end 107\n",
      "batch begin 108\n",
      "batch end 108\n",
      "batch begin 109\n",
      "batch end 109\n",
      "batch begin 110\n",
      "batch end 110\n",
      "batch begin 111\n",
      "batch end 111\n",
      "batch begin 112\n",
      "batch end 112\n",
      "batch begin 113\n",
      "batch end 113\n",
      "batch begin 114\n",
      "batch end 114\n",
      "batch begin 115\n",
      "batch end 115\n",
      "batch begin 116\n",
      "batch end 116\n",
      "batch begin 117\n",
      "batch end 117\n",
      "batch begin 118\n",
      "batch end 118\n",
      "batch begin 119\n",
      "batch end 119\n",
      "batch begin 120\n",
      "batch end 120\n",
      "batch begin 121\n",
      "batch end 121\n",
      "batch begin 122\n",
      "batch end 122\n",
      "batch begin 123\n",
      "batch end 123\n",
      "batch begin 124\n",
      "batch end 124\n",
      "batch begin 125\n",
      "batch end 125\n",
      "batch begin 126\n",
      "batch end 126\n",
      "batch begin 127\n",
      "batch end 127\n",
      "batch begin 128\n",
      "batch end 128\n",
      "batch begin 129\n",
      "batch end 129\n",
      "batch begin 130\n",
      "batch end 130\n",
      "batch begin 131\n",
      "batch end 131\n",
      "batch begin 132\n",
      "batch end 132\n",
      "batch begin 133\n",
      "batch end 133\n",
      "batch begin 134\n",
      "batch end 134\n",
      "batch begin 135\n",
      "batch end 135\n",
      "batch begin 136\n",
      "batch end 136\n",
      "batch begin 137\n",
      "batch end 137\n",
      "batch begin 138\n",
      "batch end 138\n",
      "batch begin 139\n",
      "batch end 139\n",
      "batch begin 140\n",
      "batch end 140\n",
      "batch begin 141\n",
      "batch end 141\n",
      "batch begin 142\n",
      "batch end 142\n",
      "batch begin 143\n",
      "batch end 143\n",
      "batch begin 144\n",
      "batch end 144\n",
      "batch begin 145\n",
      "batch end 145\n",
      "batch begin 146\n",
      "batch end 146\n",
      "batch begin 147\n",
      "batch end 147\n",
      "batch begin 148\n",
      "batch end 148\n",
      "batch begin 149\n",
      "batch end 149\n",
      "batch begin 150\n",
      "batch end 150\n",
      "batch begin 151\n",
      "batch end 151\n",
      "batch begin 152\n",
      "batch end 152\n",
      "batch begin 153\n",
      "batch end 153\n",
      "batch begin 154\n",
      "batch end 154\n",
      "batch begin 155\n",
      "batch end 155\n",
      "batch begin 156\n",
      "batch end 156\n",
      "batch begin 157\n",
      "batch end 157\n",
      "batch begin 158\n",
      "batch end 158\n",
      "batch begin 159\n",
      "batch end 159\n",
      "batch begin 160\n",
      "batch end 160\n",
      "batch begin 161\n",
      "batch end 161\n",
      "batch begin 162\n",
      "batch end 162\n",
      "batch begin 163\n",
      "batch end 163\n",
      "batch begin 164\n",
      "batch end 164\n",
      "batch begin 165\n",
      "batch end 165\n",
      "batch begin 166\n",
      "batch end 166\n",
      "batch begin 167\n",
      "batch end 167\n",
      "batch begin 168\n",
      "batch end 168\n",
      "batch begin 169\n",
      "batch end 169\n",
      "batch begin 170\n",
      "batch end 170\n",
      "batch begin 171\n",
      "batch end 171\n",
      "batch begin 172\n",
      "batch end 172\n",
      "batch begin 173\n",
      "batch end 173\n",
      "batch begin 174\n",
      "batch end 174\n",
      "batch begin 175\n",
      "batch end 175\n",
      "batch begin 176\n",
      "batch end 176\n",
      "batch begin 177\n",
      "batch end 177\n",
      "batch begin 178\n",
      "batch end 178\n",
      "batch begin 179\n",
      "batch end 179\n",
      "batch begin 180\n",
      "batch end 180\n",
      "batch begin 181\n",
      "batch end 181\n",
      "batch begin 182\n",
      "batch end 182\n",
      "batch begin 183\n",
      "batch end 183\n",
      "batch begin 184\n",
      "batch end 184\n",
      "batch begin 185\n",
      "batch end 185\n",
      "batch begin 186\n",
      "batch end 186\n",
      "batch begin 187\n",
      "batch end 187\n",
      "batch begin 188\n",
      "batch end 188\n",
      "batch begin 189\n",
      "batch end 189\n",
      "batch begin 190\n",
      "batch end 190\n",
      "batch begin 191\n",
      "batch end 191\n",
      "batch begin 192\n",
      "batch end 192\n",
      "batch begin 193\n",
      "batch end 193\n",
      "batch begin 194\n",
      "batch end 194\n",
      "batch begin 195\n",
      "batch end 195\n",
      "batch begin 196\n",
      "batch end 196\n",
      "batch begin 197\n",
      "batch end 197\n",
      "batch begin 198\n",
      "batch end 198\n",
      "batch begin 199\n",
      "batch end 199\n",
      "batch begin 200\n",
      "batch end 200\n",
      "batch begin 201\n",
      "batch end 201\n",
      "batch begin 202\n",
      "batch end 202\n",
      "batch begin 203\n",
      "batch end 203\n",
      "batch begin 204\n",
      "batch end 204\n",
      "batch begin 205\n",
      "batch end 205\n",
      "batch begin 206\n",
      "batch end 206\n",
      "batch begin 207\n",
      "batch end 207\n",
      "batch begin 208\n",
      "batch end 208\n",
      "batch begin 209\n",
      "batch end 209\n",
      "batch begin 210\n",
      "batch end 210\n",
      "batch begin 211\n",
      "batch end 211\n",
      "batch begin 212\n",
      "batch end 212\n",
      "batch begin 213\n",
      "batch end 213\n",
      "batch begin 214\n",
      "batch end 214\n",
      "batch begin 215\n",
      "batch end 215\n",
      "batch begin 216\n",
      "batch end 216\n",
      "batch begin 217\n",
      "batch end 217\n",
      "batch begin 218\n",
      "batch end 218\n",
      "batch begin 219\n",
      "batch end 219\n",
      "batch begin 220\n",
      "batch end 220\n",
      "batch begin 221\n",
      "batch end 221\n",
      "batch begin 222\n",
      "batch end 222\n",
      "batch begin 223\n",
      "batch end 223\n",
      "batch begin 224\n",
      "batch end 224\n",
      "batch begin 225\n",
      "batch end 225\n",
      "batch begin 226\n",
      "batch end 226\n",
      "batch begin 227\n",
      "batch end 227\n",
      "batch begin 228\n",
      "batch end 228\n",
      "batch begin 229\n",
      "batch end 229\n",
      "batch begin 230\n",
      "batch end 230\n",
      "batch begin 231\n",
      "batch end 231\n",
      "batch begin 232\n",
      "batch end 232\n",
      "batch begin 233\n",
      "batch end 233\n",
      "batch begin 234\n",
      "batch end 234\n",
      "batch begin 235\n",
      "batch end 235\n",
      "batch begin 236\n",
      "batch end 236\n",
      "batch begin 237\n",
      "batch end 237\n",
      "batch begin 238\n",
      "batch end 238\n",
      "batch begin 239\n",
      "batch end 239\n",
      "batch begin 240\n",
      "batch end 240\n",
      "batch begin 241\n",
      "batch end 241\n",
      "batch begin 242\n",
      "batch end 242\n",
      "batch begin 243\n",
      "batch end 243\n",
      "batch begin 244\n",
      "batch end 244\n",
      "batch begin 245\n",
      "batch end 245\n",
      "batch begin 246\n",
      "batch end 246\n",
      "batch begin 247\n",
      "batch end 247\n",
      "batch begin 248\n",
      "batch end 248\n",
      "batch begin 249\n",
      "batch end 249\n",
      "batch begin 250\n",
      "batch end 250\n",
      "batch begin 251\n",
      "batch end 251\n",
      "batch begin 252\n",
      "batch end 252\n",
      "batch begin 253\n",
      "batch end 253\n",
      "batch begin 254\n",
      "batch end 254\n",
      "batch begin 255\n",
      "batch end 255\n",
      "256/256 - 202s - loss: 1.7025 - sparse_categorical_accuracy: 0.3911 - val_loss: 1.7423 - val_sparse_categorical_accuracy: 0.3615\n",
      "Epoch 2/2\n",
      "epoch begin 1\n",
      "batch begin 0\n",
      "batch end 0\n",
      "batch begin 1\n",
      "batch end 1\n",
      "batch begin 2\n",
      "batch end 2\n",
      "batch begin 3\n",
      "batch end 3\n",
      "batch begin 4\n",
      "batch end 4\n",
      "batch begin 5\n",
      "batch end 5\n",
      "batch begin 6\n",
      "batch end 6\n",
      "batch begin 7\n",
      "batch end 7\n",
      "batch begin 8\n",
      "batch end 8\n",
      "batch begin 9\n",
      "batch end 9\n",
      "batch begin 10\n",
      "batch end 10\n",
      "batch begin 11\n",
      "batch end 11\n",
      "batch begin 12\n",
      "batch end 12\n",
      "batch begin 13\n",
      "batch end 13\n",
      "batch begin 14\n",
      "batch end 14\n",
      "batch begin 15\n",
      "batch end 15\n",
      "batch begin 16\n",
      "batch end 16\n",
      "batch begin 17\n",
      "batch end 17\n",
      "batch begin 18\n",
      "batch end 18\n",
      "batch begin 19\n",
      "batch end 19\n",
      "batch begin 20\n",
      "batch end 20\n",
      "batch begin 21\n",
      "batch end 21\n",
      "batch begin 22\n",
      "batch end 22\n",
      "batch begin 23\n",
      "batch end 23\n",
      "batch begin 24\n",
      "batch end 24\n",
      "batch begin 25\n",
      "batch end 25\n",
      "batch begin 26\n",
      "batch end 26\n",
      "batch begin 27\n",
      "batch end 27\n",
      "batch begin 28\n",
      "batch end 28\n",
      "batch begin 29\n",
      "batch end 29\n",
      "batch begin 30\n",
      "batch end 30\n",
      "batch begin 31\n",
      "batch end 31\n",
      "batch begin 32\n",
      "batch end 32\n",
      "batch begin 33\n",
      "batch end 33\n",
      "batch begin 34\n",
      "batch end 34\n",
      "batch begin 35\n",
      "batch end 35\n",
      "batch begin 36\n",
      "batch end 36\n",
      "batch begin 37\n",
      "batch end 37\n",
      "batch begin 38\n",
      "batch end 38\n",
      "batch begin 39\n",
      "batch end 39\n",
      "batch begin 40\n",
      "batch end 40\n",
      "batch begin 41\n",
      "batch end 41\n",
      "batch begin 42\n",
      "batch end 42\n",
      "batch begin 43\n",
      "batch end 43\n",
      "batch begin 44\n",
      "batch end 44\n",
      "batch begin 45\n",
      "batch end 45\n",
      "batch begin 46\n",
      "batch end 46\n",
      "batch begin 47\n",
      "batch end 47\n",
      "batch begin 48\n",
      "batch end 48\n",
      "batch begin 49\n",
      "batch end 49\n",
      "batch begin 50\n",
      "batch end 50\n",
      "batch begin 51\n",
      "batch end 51\n",
      "batch begin 52\n",
      "batch end 52\n",
      "batch begin 53\n",
      "batch end 53\n",
      "batch begin 54\n",
      "batch end 54\n",
      "batch begin 55\n",
      "batch end 55\n",
      "batch begin 56\n",
      "batch end 56\n",
      "batch begin 57\n",
      "batch end 57\n",
      "batch begin 58\n",
      "batch end 58\n",
      "batch begin 59\n",
      "batch end 59\n",
      "batch begin 60\n",
      "batch end 60\n",
      "batch begin 61\n",
      "batch end 61\n",
      "batch begin 62\n",
      "batch end 62\n",
      "batch begin 63\n",
      "batch end 63\n",
      "batch begin 64\n",
      "batch end 64\n",
      "batch begin 65\n",
      "batch end 65\n",
      "batch begin 66\n",
      "batch end 66\n",
      "batch begin 67\n",
      "batch end 67\n",
      "batch begin 68\n",
      "batch end 68\n",
      "batch begin 69\n",
      "batch end 69\n",
      "batch begin 70\n",
      "batch end 70\n",
      "batch begin 71\n",
      "batch end 71\n",
      "batch begin 72\n",
      "batch end 72\n",
      "batch begin 73\n",
      "batch end 73\n",
      "batch begin 74\n",
      "batch end 74\n",
      "batch begin 75\n",
      "batch end 75\n",
      "batch begin 76\n",
      "batch end 76\n",
      "batch begin 77\n",
      "batch end 77\n",
      "batch begin 78\n",
      "batch end 78\n",
      "batch begin 79\n",
      "batch end 79\n",
      "batch begin 80\n",
      "batch end 80\n",
      "batch begin 81\n",
      "batch end 81\n",
      "batch begin 82\n",
      "batch end 82\n",
      "batch begin 83\n",
      "batch end 83\n",
      "batch begin 84\n",
      "batch end 84\n",
      "batch begin 85\n",
      "batch end 85\n",
      "batch begin 86\n",
      "batch end 86\n",
      "batch begin 87\n",
      "batch end 87\n",
      "batch begin 88\n",
      "batch end 88\n",
      "batch begin 89\n",
      "batch end 89\n",
      "batch begin 90\n",
      "batch end 90\n",
      "batch begin 91\n",
      "batch end 91\n",
      "batch begin 92\n",
      "batch end 92\n",
      "batch begin 93\n",
      "batch end 93\n",
      "batch begin 94\n",
      "batch end 94\n",
      "batch begin 95\n",
      "batch end 95\n",
      "batch begin 96\n",
      "batch end 96\n",
      "batch begin 97\n",
      "batch end 97\n",
      "batch begin 98\n",
      "batch end 98\n",
      "batch begin 99\n",
      "batch end 99\n",
      "batch begin 100\n",
      "batch end 100\n",
      "batch begin 101\n",
      "batch end 101\n",
      "batch begin 102\n",
      "batch end 102\n",
      "batch begin 103\n",
      "batch end 103\n",
      "batch begin 104\n",
      "batch end 104\n",
      "batch begin 105\n",
      "batch end 105\n",
      "batch begin 106\n",
      "batch end 106\n",
      "batch begin 107\n",
      "batch end 107\n",
      "batch begin 108\n",
      "batch end 108\n",
      "batch begin 109\n",
      "batch end 109\n",
      "batch begin 110\n",
      "batch end 110\n",
      "batch begin 111\n",
      "batch end 111\n",
      "batch begin 112\n",
      "batch end 112\n",
      "batch begin 113\n",
      "batch end 113\n",
      "batch begin 114\n",
      "batch end 114\n",
      "batch begin 115\n",
      "batch end 115\n",
      "batch begin 116\n",
      "batch end 116\n",
      "batch begin 117\n",
      "batch end 117\n",
      "batch begin 118\n",
      "batch end 118\n",
      "batch begin 119\n",
      "batch end 119\n",
      "batch begin 120\n",
      "batch end 120\n",
      "batch begin 121\n",
      "batch end 121\n",
      "batch begin 122\n",
      "batch end 122\n",
      "batch begin 123\n",
      "batch end 123\n",
      "batch begin 124\n",
      "batch end 124\n",
      "batch begin 125\n",
      "batch end 125\n",
      "batch begin 126\n",
      "batch end 126\n",
      "batch begin 127\n",
      "batch end 127\n",
      "batch begin 128\n",
      "batch end 128\n",
      "batch begin 129\n",
      "batch end 129\n",
      "batch begin 130\n",
      "batch end 130\n",
      "batch begin 131\n",
      "batch end 131\n",
      "batch begin 132\n",
      "batch end 132\n",
      "batch begin 133\n",
      "batch end 133\n",
      "batch begin 134\n",
      "batch end 134\n",
      "batch begin 135\n",
      "batch end 135\n",
      "batch begin 136\n",
      "batch end 136\n",
      "batch begin 137\n",
      "batch end 137\n",
      "batch begin 138\n",
      "batch end 138\n",
      "batch begin 139\n",
      "batch end 139\n",
      "batch begin 140\n",
      "batch end 140\n",
      "batch begin 141\n",
      "batch end 141\n",
      "batch begin 142\n",
      "batch end 142\n",
      "batch begin 143\n",
      "batch end 143\n",
      "batch begin 144\n",
      "batch end 144\n",
      "batch begin 145\n",
      "batch end 145\n",
      "batch begin 146\n",
      "batch end 146\n",
      "batch begin 147\n",
      "batch end 147\n",
      "batch begin 148\n",
      "batch end 148\n",
      "batch begin 149\n",
      "batch end 149\n",
      "batch begin 150\n",
      "batch end 150\n",
      "batch begin 151\n",
      "batch end 151\n",
      "batch begin 152\n",
      "batch end 152\n",
      "batch begin 153\n",
      "batch end 153\n",
      "batch begin 154\n",
      "batch end 154\n",
      "batch begin 155\n",
      "batch end 155\n",
      "batch begin 156\n",
      "batch end 156\n",
      "batch begin 157\n",
      "batch end 157\n",
      "batch begin 158\n",
      "batch end 158\n",
      "batch begin 159\n",
      "batch end 159\n",
      "batch begin 160\n",
      "batch end 160\n",
      "batch begin 161\n",
      "batch end 161\n",
      "batch begin 162\n",
      "batch end 162\n",
      "batch begin 163\n",
      "batch end 163\n",
      "batch begin 164\n",
      "batch end 164\n",
      "batch begin 165\n",
      "batch end 165\n",
      "batch begin 166\n",
      "batch end 166\n",
      "batch begin 167\n",
      "batch end 167\n",
      "batch begin 168\n",
      "batch end 168\n",
      "batch begin 169\n",
      "batch end 169\n",
      "batch begin 170\n",
      "batch end 170\n",
      "batch begin 171\n",
      "batch end 171\n",
      "batch begin 172\n",
      "batch end 172\n",
      "batch begin 173\n",
      "batch end 173\n",
      "batch begin 174\n",
      "batch end 174\n",
      "batch begin 175\n",
      "batch end 175\n",
      "batch begin 176\n",
      "batch end 176\n",
      "batch begin 177\n",
      "batch end 177\n",
      "batch begin 178\n",
      "batch end 178\n",
      "batch begin 179\n",
      "batch end 179\n",
      "batch begin 180\n",
      "batch end 180\n",
      "batch begin 181\n",
      "batch end 181\n",
      "batch begin 182\n",
      "batch end 182\n",
      "batch begin 183\n",
      "batch end 183\n",
      "batch begin 184\n",
      "batch end 184\n",
      "batch begin 185\n",
      "batch end 185\n",
      "batch begin 186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch end 186\n",
      "batch begin 187\n",
      "batch end 187\n",
      "batch begin 188\n",
      "batch end 188\n",
      "batch begin 189\n",
      "batch end 189\n",
      "batch begin 190\n",
      "batch end 190\n",
      "batch begin 191\n",
      "batch end 191\n",
      "batch begin 192\n",
      "batch end 192\n",
      "batch begin 193\n",
      "batch end 193\n",
      "batch begin 194\n",
      "batch end 194\n",
      "batch begin 195\n",
      "batch end 195\n",
      "batch begin 196\n",
      "batch end 196\n",
      "batch begin 197\n",
      "batch end 197\n",
      "batch begin 198\n",
      "batch end 198\n",
      "batch begin 199\n",
      "batch end 199\n",
      "batch begin 200\n",
      "batch end 200\n",
      "batch begin 201\n",
      "batch end 201\n",
      "batch begin 202\n",
      "batch end 202\n",
      "batch begin 203\n",
      "batch end 203\n",
      "batch begin 204\n",
      "batch end 204\n",
      "batch begin 205\n",
      "batch end 205\n",
      "batch begin 206\n",
      "batch end 206\n",
      "batch begin 207\n",
      "batch end 207\n",
      "batch begin 208\n",
      "batch end 208\n",
      "batch begin 209\n",
      "batch end 209\n",
      "batch begin 210\n",
      "batch end 210\n",
      "batch begin 211\n",
      "batch end 211\n",
      "batch begin 212\n",
      "batch end 212\n",
      "batch begin 213\n",
      "batch end 213\n",
      "batch begin 214\n",
      "batch end 214\n",
      "batch begin 215\n",
      "batch end 215\n",
      "batch begin 216\n",
      "batch end 216\n",
      "batch begin 217\n",
      "batch end 217\n",
      "batch begin 218\n",
      "batch end 218\n",
      "batch begin 219\n",
      "batch end 219\n",
      "batch begin 220\n",
      "batch end 220\n",
      "batch begin 221\n",
      "batch end 221\n",
      "batch begin 222\n",
      "batch end 222\n",
      "batch begin 223\n",
      "batch end 223\n",
      "batch begin 224\n",
      "batch end 224\n",
      "batch begin 225\n",
      "batch end 225\n",
      "batch begin 226\n",
      "batch end 226\n",
      "batch begin 227\n",
      "batch end 227\n",
      "batch begin 228\n",
      "batch end 228\n",
      "batch begin 229\n",
      "batch end 229\n",
      "batch begin 230\n",
      "batch end 230\n",
      "batch begin 231\n",
      "batch end 231\n",
      "batch begin 232\n",
      "batch end 232\n",
      "batch begin 233\n",
      "batch end 233\n",
      "batch begin 234\n",
      "batch end 234\n",
      "batch begin 235\n",
      "batch end 235\n",
      "batch begin 236\n",
      "batch end 236\n",
      "batch begin 237\n",
      "batch end 237\n",
      "batch begin 238\n",
      "batch end 238\n",
      "batch begin 239\n",
      "batch end 239\n",
      "batch begin 240\n",
      "batch end 240\n",
      "batch begin 241\n",
      "batch end 241\n",
      "batch begin 242\n",
      "batch end 242\n",
      "batch begin 243\n",
      "batch end 243\n",
      "batch begin 244\n",
      "batch end 244\n",
      "batch begin 245\n",
      "batch end 245\n",
      "batch begin 246\n",
      "batch end 246\n",
      "batch begin 247\n",
      "batch end 247\n",
      "batch begin 248\n",
      "batch end 248\n",
      "batch begin 249\n",
      "batch end 249\n",
      "batch begin 250\n",
      "batch end 250\n",
      "batch begin 251\n",
      "batch end 251\n",
      "batch begin 252\n",
      "batch end 252\n",
      "batch begin 253\n",
      "batch end 253\n",
      "batch begin 254\n",
      "batch end 254\n",
      "batch begin 255\n",
      "batch end 255\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt\n",
      "===============================================================================================================\n",
      "\n",
      "[2021-02-19T02:56:28.984456] Entering job release\n",
      "[2021-02-19T02:56:30.047651] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-02-19T02:56:30.047745] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-02-19T02:56:30.047797] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-02-19T02:56:30.048410] Running Sidecar release cmd...\n",
      "[2021-02-19T02:56:30.058348] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/mounts/workspaceblobstore/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/wd/tmpehyhayhh.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/sl-ash2-mal/azureml/dist-tf2-on-aks-arc_1613702443_c5157ce0/wd/tmpehyhayhh.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-02-19T02:56:30.186782] Removing absolute paths from host...\n",
      "[2021-02-19T02:56:30.930594] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "[2021-02-19T02:56:31.536811] Ran Sidecar release cmd.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: dist-tf2-on-aks-arc_1613702443_c5157ce0\n",
      "Web View: https://ml.azure.com/experiments/dist-tf2-on-aks-arc/runs/dist-tf2-on-aks-arc_1613702443_c5157ce0?wsid=/subscriptions/6b736da6-3246-44dd-a0b8-b5e95484633d/resourcegroups/sl-ash2/workspaces/sl-ash2-mal\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'dist-tf2-on-aks-arc_1613702443_c5157ce0',\n",
       " 'target': 'd13',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-02-19T02:40:59.963486Z',\n",
       " 'endTimeUtc': '2021-02-19T02:56:56.49202Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': '569d190c-18bd-463f-9c25-4a366de60d75',\n",
       "  'azureml.git.repository_uri': 'git@github.com:lisongshan007/AML-Kubernetes.git',\n",
       "  'mlflow.source.git.repoURL': 'git@github.com:lisongshan007/AML-Kubernetes.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': '9af78d232734dace4df94ed28a5e6888ed3905e4',\n",
       "  'mlflow.source.git.commit': '9af78d232734dace4df94ed28a5e6888ed3905e4',\n",
       "  'azureml.git.dirty': 'False',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '24d86baf-41f9-40e1-ae0d-5ae8b4c9cdfc'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__358e1d54', 'mechanism': 'Mount'}}],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--dataset-path',\n",
       "   'DatasetConsumptionConfig:input__358e1d54',\n",
       "   '--epochs',\n",
       "   '2',\n",
       "   '--global-batch-size',\n",
       "   '256',\n",
       "   '--batches-per-epoch',\n",
       "   '256',\n",
       "   '--alpha-init',\n",
       "   '0.005'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'TensorFlow',\n",
       "  'communicator': 'ParameterServer',\n",
       "  'target': 'd13',\n",
       "  'dataReferences': {},\n",
       "  'data': {'input__358e1d54': {'dataLocation': {'dataset': {'id': '24d86baf-41f9-40e1-ae0d-5ae8b4c9cdfc',\n",
       "      'name': 'cifar10',\n",
       "      'version': '1'},\n",
       "     'dataPath': None},\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'input__358e1d54',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 3,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'tf_2.4',\n",
       "   'version': 'Autosave_2021-02-15T15:31:51Z_aa6981a7',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      'python-graphviz',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'tensorflow==2.4.1',\n",
       "        'tensorflow-addons',\n",
       "        'pydot']}],\n",
       "     'name': 'azureml_9434952ae259b151800c4b71c124feb5'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': None,\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': 'FROM tensorflow/tensorflow:2.4.1-gpu\\n\\nARG CONDA_VERSION=4.7.12\\nARG PYTHON_VERSION=3.7\\nARG AZUREML_SDK_VERSION=1.13.0\\nARG INFERENCE_SCHEMA_VERSION=1.1.0\\n\\nENV LANG=C.UTF-8 LC_ALL=C.UTF-8\\nENV PATH /opt/miniconda/bin:$PATH\\nENV DEBIAN_FRONTEND=noninteractive\\n\\nRUN apt-get update --fix-missing && \\\\\\n    apt-get install -y wget bzip2 && \\\\\\n    apt-get install -y fuse && \\\\\\n    apt-get clean -y && \\\\\\n    rm -rf /var/lib/apt/lists/*\\n\\nRUN useradd --create-home dockeruser\\nWORKDIR /home/dockeruser\\nUSER dockeruser\\n\\nRUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-${CONDA_VERSION}-Linux-x86_64.sh -O ~/miniconda.sh && \\\\\\n    /bin/bash ~/miniconda.sh -b -p ~/miniconda && \\\\\\n    rm ~/miniconda.sh && \\\\\\n    ~/miniconda/bin/conda clean -tipsy\\nENV PATH=\"/home/dockeruser/miniconda/bin/:${PATH}\"\\n',\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None},\n",
       "  'tensorflow': {'workerCount': 3, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/55_azureml-execution-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt?sv=2019-02-02&sr=b&sig=hLDJq8eF9wM2OuQKffI0hdFjG3Ps633vomfDHdSxGe8%3D&st=2021-02-19T02%3A47%3A10Z&se=2021-02-19T10%3A57%3A10Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/55_azureml-execution-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt?sv=2019-02-02&sr=b&sig=x22KLI0DRy1Gl5p6JZISBBjAbFuSRUxqdgho8ndISJU%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/55_azureml-execution-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt?sv=2019-02-02&sr=b&sig=YRX7SD4Xg2LfpyKq5qgzAD6Gg5LEGCA%2FrH8GlPuIvIM%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/65_job_prep-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt?sv=2019-02-02&sr=b&sig=iktKnYa%2F5e7%2FNuZYB87Ykg9DbjFKVNUVCQaLXaFQR3s%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/65_job_prep-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt?sv=2019-02-02&sr=b&sig=087GSSoNZ5RdzNuxxrJW14Uk4AG2NDdv2btYpa9qEdo%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/65_job_prep-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt?sv=2019-02-02&sr=b&sig=pGy4HNpqkDTlWCX0Mi%2Bx7CAF%2F%2Bm82ZmmnkpiGK8jpwk%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log-ps-0.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/70_driver_log-ps-0.txt?sv=2019-02-02&sr=b&sig=9ZAHSDujPOv5EPVWEwobtzq3TxBde4Aav1y0bF05rwI%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log-worker-0.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/70_driver_log-worker-0.txt?sv=2019-02-02&sr=b&sig=9CxRaAaArNMQ0usrWH7TUriPaZDM5uIKmiGtp4YNKtA%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log-worker-1.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/70_driver_log-worker-1.txt?sv=2019-02-02&sr=b&sig=Pd5Ytx4wYEL%2BEPTVfR4QWNvMBAGjG%2FtA%2FVM0%2F5EDVF0%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/70_driver_log-worker-2.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/70_driver_log-worker-2.txt?sv=2019-02-02&sr=b&sig=j%2BPn%2Bmt%2FUKK3hXpKw%2FwMqh%2F649DBqShsPvB%2BtuBa4xI%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/75_job_post-tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d.txt?sv=2019-02-02&sr=b&sig=vqi0yEckgPQ9mOF%2FWa6hT3zufdWroNydUDzxIbkjPLg%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/75_job_post-tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d.txt?sv=2019-02-02&sr=b&sig=B5xgvHBNRu%2Bj4I%2BCDcmjlDiBi3NR0RyI1p1eZm8p8Tg%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/75_job_post-tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d.txt?sv=2019-02-02&sr=b&sig=KI5A9gEl9ovZU788LW7MZnHGAHBQGurkVIVmEnLB0AM%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=RrbtsPptbiQbF9npNBE25ORV7xZw6mqxnQBRo6WG7wA%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=Y9pS9d4EYlhFycmvi0bkvZPevVTB8v8mKaYWfPHqDto%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=vXMlhti%2B9myL%2BWmOGsf6RvrBsbjq3Q3Zb5qOsi%2BTJKM%3D&st=2021-02-19T02%3A47%3A10Z&se=2021-02-19T10%3A57%3A10Z&sp=r',\n",
       "  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=Z2FwFgXx8BMtS1mOxHUP00fO7KHIuGajdlHIQkzJTlQ%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=g3KvyFLV84r3sgYzdzsQIGih6hJs6mlgu%2BoW%2BR71%2FQw%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=mXDiHmyI%2FX7TipiisqSUCMiaj81uvLGlN1bStVfO0PY%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/ps0_366_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/ps0_366_azureml.log?sv=2019-02-02&sr=b&sig=KKIcvp8wnvxh5nvfJf7ykAApCGRy%2B18C8eRSToVOmYI%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/all.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/all.log?sv=2019-02-02&sr=b&sig=mNCgP94N3wQ%2B14a3%2FoJg3XLC7sf14RNMCwExn%2FG9%2Ba8%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/task.enter_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=6oKMiNc81XnHsGRVE%2FFHOMowJpXifdqtZAUDqESAm%2FQ%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/task.exit_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_16073b0ab0f5023d82c74e2a2fcec4a47b34a8622966f122479d5082ad253048_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=2HRZgk7aKS2s5Hz9Gv67%2F5O1We98zTVl%2Bro6xCMpVRo%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/all.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/all.log?sv=2019-02-02&sr=b&sig=S%2B5K0XKAvZyZxaBfs4JblUYAHIqPw2rCMznKakyV2Rc%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/task.enter_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=IIJQabxWCA468FpJyxKonLXu0WmuH7guHOeiNBDR0Z4%3D&st=2021-02-19T02%3A47%3A11Z&se=2021-02-19T10%3A57%3A11Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/task.exit_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_46740d19dd1e592726e14c649f6e61e8a5b76342a7073be368c287fbb0eb3b8c_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=HjZssWAsHZuSX0O0704PvVt1t1YaQ8FoXTiPywfe0Sw%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/all.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/all.log?sv=2019-02-02&sr=b&sig=l0x2H5tUDNmLgPPAKbZ895VNoHNiIDDQ7XSqLXc1gVo%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/task.enter_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=Ml%2FbbJUnj%2BPU7Kz58yeQ%2Fe0%2BAAhRDg1DF%2F3TauLcWvs%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/task.exit_contexts.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/sidecar/tvmps_95854dc4e473e4a7432f7a230c52d8347a0795a3625484abf350ae1090799324_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=kSNkJ6uVMc4cuiI%2BZbb%2BMR8DCFhedJHT%2FRcPTVaxJLw%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/worker0_397_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/worker0_397_azureml.log?sv=2019-02-02&sr=b&sig=cnQ14%2B%2BVXjDkn2ntDJ3Qbm3Yb%2Bb9V8n9BYaeWb7F2yg%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/worker1_348_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/worker1_348_azureml.log?sv=2019-02-02&sr=b&sig=nepMnyp7T4pYqGeo7IpKuGoO3G%2BNsQPmJJVthRKtD3U%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r',\n",
       "  'logs/azureml/worker2_347_azureml.log': 'https://slash2mal3094941854.blob.core.windows.net/azureml/ExperimentRun/dcid.dist-tf2-on-aks-arc_1613702443_c5157ce0/logs/azureml/worker2_347_azureml.log?sv=2019-02-02&sr=b&sig=%2BN12IKdxHSMZYGg9AzsbAnqOtU4NdqzDiWL83lG%2B%2BN0%3D&st=2021-02-19T02%3A47%3A12Z&se=2021-02-19T10%3A57%3A12Z&sp=r'},\n",
       " 'submittedBy': 'Songshan Li'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(config=src)\n",
    "run.wait_for_completion(show_output=True) # this provides a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  the model is saved at path \"outputs/001\"\n",
    "registered_model_name = 'cifar10tf'\n",
    "model = run.register_model(model_name=registered_model_name, model_path='outputs/001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The machine learning model named \"cifar10tf\" should be registered in your AML workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Registered Model\n",
    "\n",
    "To test the trained model, you can create (or use existing) a AKS cluster for serving the model using AML deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment, Workspace, Model, ComputeTarget\n",
    "from azureml.core.compute import AksCompute\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice, AksWebservice\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provision the AKS Cluster\n",
    "\n",
    "This is a one time setup. You can reuse this cluster for multiple deployments after it has been created. If you delete the cluster or the resource group that contains it, then you would have to recreate it. It may take 5 mins to create a new AKS cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "using compute target:  aks-service-2\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'aks-service-2'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    is_new_compute  = False\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                    name = aks_name, \n",
    "                                    provisioning_configuration = prov_config)\n",
    "    is_new_compute  = True\n",
    "    \n",
    "print(\"using compute target: \", aks_target.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running.........................................................................................\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "env = Environment.from_conda_specification(name=\"tf_2.4\", file_path=\"tf-script/tf-24-env.yaml\")\n",
    "inference_config = InferenceConfig(entry_script='score_tf.py', environment=env)\n",
    "deploy_config = AksWebservice.deploy_configuration()\n",
    "\n",
    "#registered_model_name = \"cifar10tf_80\"\n",
    "model = ws.models[registered_model_name]\n",
    "service_name = 'cifartfservice1'\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=deploy_config,\n",
    "                       deployment_target=aks_target,\n",
    "                       overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with inputs\n",
    "\n",
    "For testing purpose, first five images from test batch are extracted. Let's take a look these pictures: \n",
    "\n",
    "A sample input has been included in cifar10_test_input.json for model testing. The outputs are probabilities  for each class. the ten labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_files = [\"test_img_0_cat.jpg\", \"test_img_1_ship.jpg\",\"test_img_2_ship.jpg\",\"test_img_3_plane.jpg\",\"test_img_4_frog.jpg\"]\n",
    "\n",
    "for img_file in img_files:\n",
    "    image = Image.open(\"test_imgs/{}\".format(img_file))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some data process, these five images are converted to json as input for the trained model. The outputs are probabilities  for each class per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.010631756857037544, 0.05487808212637901, 0.08862863481044769, 0.17179299890995026, 0.02946522831916809, 0.10520273447036743, 0.3316628038883209, 0.005262687802314758, 0.10701419413089752, 0.09546088427305222], [0.004351824056357145, 0.9802891612052917, 3.8142397897900082e-06, 1.57823469635332e-05, 5.642276391881751e-06, 6.758522204108885e-07, 2.414366463199258e-05, 6.766516889911145e-06, 0.008264408446848392, 0.007037722039967775], [0.09286026656627655, 0.3799227774143219, 0.00039583438774570823, 0.0008613724494352937, 0.0007697520195506513, 0.0001935697946464643, 0.001001340220682323, 0.0006281483802013099, 0.43021687865257263, 0.09315010905265808], [0.3268948495388031, 0.11965004354715347, 0.00022240476391743869, 0.000488616235088557, 0.0002872534969355911, 1.9691684428835288e-05, 0.00026881249505095184, 7.29254461475648e-05, 0.5433928370475769, 0.00870265532284975], [5.594985486823134e-05, 0.0007109963917173445, 0.0064894272945821285, 0.013348071835935116, 0.08071228116750717, 0.005291924346238375, 0.890500545501709, 0.001529020955786109, 0.0006719081429764628, 0.0006898975698277354]]\n"
     ]
    }
   ],
   "source": [
    "with open(\"cifar10_test_input_tf.json\", \"r\") as fp:\n",
    "    inputs_json = json.load(fp)\n",
    "inputs = json.dumps(inputs_json)\n",
    "resp = service.run(inputs)\n",
    "predicts = resp[\"predictions\"]\n",
    "print(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can easily get the predictions of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frog', 'car', 'ship', 'ship', 'frog']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "np_predicts = np.array(predicts)\n",
    "pred_indexes = np.argmax(np_predicts, 1)\n",
    "\n",
    "predict_labels = [classes[i] for i in pred_indexes]\n",
    "print(predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the newly created cluster\n",
    "\n",
    "Note: This is important if you wish to avoid the cost of this cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_new_compute:\n",
    "    aks_target.delete()\n",
    "    service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Learn how to [download model then upload to Azure Storage blobs](../AML-model-download-upload.ipynb)\n",
    "2. Learn how to [inference using KFServing with model in Azure Storage Blobs](https://aka.ms/kfas)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "pytouchEnv",
   "language": "python",
   "name": "pytouchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
