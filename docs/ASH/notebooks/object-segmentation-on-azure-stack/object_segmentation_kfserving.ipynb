{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Segmenation Inference With KFServing on ASH Clusters\n",
    "\n",
    "For this tutorial, you will deploy the model trained in [previous notebook](object_segmentation-ash.ipynb), then deploy to KFServing PytorchServer hosted by an Azure Stack Hub cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "*     Following [this notebook](object_segmentation-ash.ipynb) to train and register the parameter model in AML workspace.\n",
    "\n",
    "*     Install KFServing as described [here](KFServing-setup.md)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to KFServing PytorchServer\n",
    "\n",
    "KFServing [PytorchServer](https://github.com/kubeflow/kfserving/blob/master/python/pytorchserver/pytorchserver/model.py) needs two files: \"model.pt\" which contains \"state_dict\" of the trained model, and a custom python file which contains the network information of the trained mode.  Here, \"model.pt\" is available in AML register model as described in [this notebook](object_segmentation-ash.ipynb).  You can download to your local file system.  The python file, named \"score_model.py\" here is included in this repository. These two files are passed to inference servers through [KFServing storageUri](https://github.com/kubeflow/kfserving/blob/master/python/kfserving/kfserving/storage.py) which supports azure storage blob."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of StorageUri\n",
    "\n",
    "The two files (model.pt, score_model.py) can be uploaded to your storage account as container's blob using portal (on upload page, click advanced, choose \"upload to folder\"). The azure storage path containing these two files should be looks like \n",
    "\n",
    "```https://<storage_account_name>.blob.core.windows.net/<container_name>/<folder_name>```\n",
    "\n",
    "Note: KFServing StorageUri currently does not support Azure Stack Hub storage account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a kubernetes secret and service account for client credentials:\n",
    "\n",
    "   The data in Secret is encoded in base64. Here is a simple way to encode a plain string in base64 in Linux:\n",
    "\n",
    "<pre> $ echo -n \"mystring\" | base64 </pre>\n",
    "\n",
    "   please make sure the \"-n\" option is used. To decode:\n",
    "\n",
    "<pre> $ echo -n \"base64-string\" | base64 -d </pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile azure_secret.yaml\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: azcreds\n",
    "type: Opaque\n",
    "data:\n",
    "  AZ_CLIENT_ID: \"<base_64 encoded>\"\n",
    "  AZ_CLIENT_SECRET: \"<base_64 encoded>\"\n",
    "  AZ_SUBSCRIPTION_ID: \"<base_64 encoded>\"\n",
    "  AZ_TENANT_ID: \"<base_64 encoded>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile service_account.yaml\n",
    "apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: azuresa\n",
    "secrets:\n",
    "- name: azcreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Secret and Service Account:\n",
    "\n",
    "<pre>\n",
    "kubectl apply -f azure_secret.yaml\n",
    "\n",
    "kubectl apply -f service_account.yaml\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install InferenceService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile obj_seg_inferenceservice.yaml\n",
    "apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"obj-seg\"\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      pytorch:\n",
    "        storageUri: \"https://backupsli.blob.core.windows.net/kftorch/objectseg\"\n",
    "        modelClassName: \"Net\"\n",
    "      serviceAccountName: azuresa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Get xip.io url for Testing:\n",
    "\n",
    "If you configured DNS with xip.io as described in [KFserving installation guide](KFServing-setup.md), you can get the\n",
    "xip.io url and use a web test tool like Insomnia or Postman to test your service.\n",
    "\n",
    "*  Get host url:\n",
    "\n",
    "<pre>\n",
    "$ kubectl get ksvc\n",
    "\n",
    "NAME                                URL                                                                                          LATESTCREATED                        LATESTREADY                       READY   REASON\n",
    "obj-seg-predictor-default   http://obj-seg-predictor-default.default.10.217.119.227.xip.io   obj-seg-predictor-default-00002   obj-seg-predictor-default-00002   True\n",
    "</pre>  \n",
    "\n",
    "As displayed, host url is http://obj-seg-predictor-default.default.10.217.119.227.xip.io\n",
    "\n",
    "*  The whole url:\n",
    "\n",
    "    The whole url is composed as {host_url}/ v1/models/obj-seg:predictt\n",
    "    \n",
    "    For this particular example, it is:\n",
    "\n",
    "    http://obj-seg-predictor-default.default.10.217.119.227.xip.io/v1/models/obj-seg:predict\n",
    "    \n",
    "\n",
    "*  Test the inference service:\n",
    "\n",
    "   Once the end point is identified as describe above, you can run the same testing codes as in AML deployment cases shown in previous cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Service Using the Restful End Point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a  function to call the url end point\n",
    "\n",
    "Creae a simple help function to wrap the restful endpoint call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def service_infer(url, body, api_key):\n",
    "    headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "    req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "\n",
    "        result = response.read()\n",
    "        return result\n",
    "\n",
    "    except urllib.error.HTTPError as error:\n",
    "        print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "        # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "        print(error.info())\n",
    "        print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a Few Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://obj-seg-predictor-default.default.10.217.119.227.xip.io/v1/models/obj-seg:predict' # replace with url from your deployment\n",
    "api_key = ''  \n",
    "\n",
    "img_nums = [\"00001\",\"00002\"]\n",
    "image_paths = [\"PennFudanPed\\\\PNGImages\\\\FudanPed{}.png\".format(item) for item in img_nums]\n",
    "image_np_list = []\n",
    "for image_path in image_paths:\n",
    "    img = Image.open(image_path)\n",
    "    img.show(\"input_image\")\n",
    "    img_rgb = img.convert(\"RGB\")\n",
    "    img_tensor = F.to_tensor(img_rgb)\n",
    "    img_np = img_tensor.numpy()\n",
    "    image_np_list.append(img_np.tolist())\n",
    "\n",
    "request = {\"instances\": image_np_list}\n",
    "inputs = json.dumps(request)\n",
    "\n",
    "body = str.encode(inputs)\n",
    "resp = service_infer(url, body, api_key)\n",
    "p_obj = json.loads(resp)\n",
    "\n",
    "# put the model in evaluation mode\n",
    "for instance_pred in p_obj[\"predictions\"]:\n",
    "    image_data = instance_pred[\"masks\"]\n",
    "    img_np = np.array(image_data)\n",
    "    output = Image.fromarray(img_np)\n",
    "    output.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "pythonproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
